<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/24/2024-05-04-cgroup-v2-buffer-io/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/24/2024-05-04-cgroup-v2-buffer-io/" class="post-title-link" itemprop="url">Cgroup DIsk IO Deep Dive</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-24 19:49:04" itemprop="dateCreated datePublished" datetime="2024-04-24T19:49:04+08:00">2024-04-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-12 18:46:04" itemprop="dateModified" datetime="2024-05-12T18:46:04+08:00">2024-05-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/system/" itemprop="url" rel="index"><span itemprop="name">system</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="What-the-cgroup-init-difference-between-v1-and-v2"><a href="#What-the-cgroup-init-difference-between-v1-and-v2" class="headerlink" title="What the cgroup init difference between v1 and v2"></a>What the cgroup init difference between v1 and v2</h3><p>We know the basic buffer IO flow is to write the data into a dirty page on memory, then an asynchronous writeback thread will flush the dirty page onto the disk. Unlike the direct IO, the buffer IO is not only controlled by the io controller but also controlled by the memory controller.</p>
<p>In March 2014, kernel merged the pr<a target="_blank" rel="noopener" href="https://lwn.net/Articles/592434/"> cgroup: implement unified hierarchy</a> about unified architecture in cgroup, that is the basic design of cgroup v2.</p>
<p>There is the code of the main process of cgroup init. In the process of cgroup init in the function of “cgroup_init”, after setting up the cgroup root, initiating the subsystem of the cgroups and creating the mountpoints, the kernel registers the different cgroup filesystems on that mount point according to different cgroup types:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">int __init cgroup_init(void)</span><br><span class="line">&#123;</span><br><span class="line">           …</span><br><span class="line">    	BUG_ON(cgroup_setup_root(&amp;cgrp_dfl_root, 0));</span><br><span class="line">           …</span><br><span class="line">	for_each_subsys(ss, ssid) &#123;</span><br><span class="line">		if (ss-&gt;early_init) &#123;</span><br><span class="line">			struct cgroup_subsys_state *css =</span><br><span class="line">				init_css_set.subsys[ss-&gt;id];</span><br><span class="line"></span><br><span class="line">			css-&gt;id = cgroup_idr_alloc(&amp;ss-&gt;css_idr, css, 1, 2,</span><br><span class="line">						   GFP_KERNEL);</span><br><span class="line">			BUG_ON(css-&gt;id &lt; 0);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			cgroup_init_subsys(ss, false);</span><br><span class="line">		&#125;</span><br><span class="line">                      …</span><br><span class="line">		if (ss-&gt;dfl_cftypes == ss-&gt;legacy_cftypes) &#123;</span><br><span class="line">			WARN_ON(cgroup_add_cftypes(ss, ss-&gt;dfl_cftypes));</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			WARN_ON(cgroup_add_dfl_cftypes(ss, ss-&gt;dfl_cftypes));</span><br><span class="line">			WARN_ON(cgroup_add_legacy_cftypes(ss, ss-&gt;legacy_cftypes));</span><br><span class="line">		&#125;</span><br><span class="line">           &#125;</span><br><span class="line">           …</span><br><span class="line">	WARN_ON(sysfs_create_mount_point(fs_kobj, &quot;cgroup&quot;));</span><br><span class="line">	WARN_ON(register_filesystem(&amp;cgroup_fs_type));</span><br><span class="line">	WARN_ON(register_filesystem(&amp;cgroup2_fs_type));</span><br><span class="line">	WARN_ON(!proc_create_single(&quot;cgroups&quot;, 0, NULL, proc_cgroupstats_show));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>When register_filesystem, cgroup v1 and v2 register different filesystem operations:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">static const struct fs_context_operations cgroup_fs_context_ops = &#123;</span><br><span class="line">	.free		= cgroup_fs_context_free,</span><br><span class="line">	.parse_param	= cgroup2_parse_param,</span><br><span class="line">	.get_tree	= cgroup_get_tree,</span><br><span class="line">	.reconfigure	= cgroup_reconfigure,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">static const struct fs_context_operations cgroup1_fs_context_ops = &#123;</span><br><span class="line">	.free		= cgroup_fs_context_free,</span><br><span class="line">	.parse_param	= cgroup1_parse_param,</span><br><span class="line">	.get_tree	= cgroup1_get_tree,</span><br><span class="line">	.reconfigure	= cgroup1_reconfigure,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


<p>When doing the mount, the kernel tries to call the .get_tree interface to bind the filesystem on the directory by do_new_mount -&gt; vfs_get_tree -&gt; fc-&gt;ops-&gt;get_tree(fc). There are the different call path of the cgroup v1 and v2 implementations of .get_tree:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">int cgroup1_get_tree(struct fs_context *fc)</span><br><span class="line">&#123;</span><br><span class="line">…</span><br><span class="line">          	ret = cgroup1_root_to_use(fc);</span><br><span class="line">	if (!ret)</span><br><span class="line">		ret = cgroup_do_get_tree(fc);</span><br><span class="line">…</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * The guts of cgroup1 mount - find or create cgroup_root to use.</span><br><span class="line"> */</span><br><span class="line">static int cgroup1_root_to_use(struct fs_context *fc)</span><br><span class="line">&#123;</span><br><span class="line">	for_each_root(root) &#123;</span><br><span class="line"></span><br><span class="line">		/*</span><br><span class="line">		 * If we asked for a name then it must match.  Also, if</span><br><span class="line">		 * name matches but sybsys_mask doesn&#x27;t, we should fail.</span><br><span class="line">		 * Remember whether name matched.</span><br><span class="line">		 */</span><br><span class="line">		if (ctx-&gt;name) &#123;</span><br><span class="line">			if (strcmp(ctx-&gt;name, root-&gt;name))</span><br><span class="line">				continue;</span><br><span class="line">			name_match = true;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		ctx-&gt;root = root;</span><br><span class="line">		return 0;</span><br><span class="line">	&#125;</span><br><span class="line">            /*</span><br><span class="line">	 * No such thing, create a new one.  </span><br><span class="line">	 */</span><br><span class="line">	root = kzalloc(sizeof(*root), GFP_KERNEL);</span><br><span class="line">	if (!root)</span><br><span class="line">		return -ENOMEM;</span><br><span class="line"></span><br><span class="line">	ctx-&gt;root = root;</span><br><span class="line">	init_cgroup_root(ctx);</span><br><span class="line"></span><br><span class="line">	ret = cgroup_setup_root(root, ctx-&gt;subsys_mask);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Because the mountpoinst are different names, every mount will produce a new cgroup root and the cgroup root link to the subsys of cgroup. The cgroup_root represents the root of a cgroup hierarchy which is organized as a tree. Every tree is a hierarchy structure and it is independent. The child cgroups from cgroup root can only inherit the sussystem with parent cgroup and can not quickly visit other subsystems in cgroup v1. Though it has a root_list to store all the cgroup root, it is hard to cooperate with each other. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * A cgroup_root represents the root of a cgroup hierarchy, and may be</span><br><span class="line"> * associated with a kernfs_root to form an active hierarchy.  This is</span><br><span class="line"> * internal to cgroup core.  Don&#x27;t access directly from controllers.</span><br><span class="line"> */</span><br><span class="line">struct cgroup_root &#123;</span><br><span class="line">	struct kernfs_root *kf_root;</span><br><span class="line"></span><br><span class="line">	/* The bitmask of subsystems attached to this hierarchy */</span><br><span class="line">	unsigned int subsys_mask;</span><br><span class="line"></span><br><span class="line">	/* Unique id for this hierarchy. */</span><br><span class="line">	int hierarchy_id;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * The root cgroup. The containing cgroup_root will be destroyed on its</span><br><span class="line">	 * release. cgrp-&gt;ancestors[0] will be used overflowing into the</span><br><span class="line">	 * following field. cgrp_ancestor_storage must immediately follow.</span><br><span class="line">	 */</span><br><span class="line">	struct cgroup cgrp;</span><br><span class="line"></span><br><span class="line">	/* must follow cgrp for cgrp-&gt;ancestors[0], see above */</span><br><span class="line">	struct cgroup *cgrp_ancestor_storage;</span><br><span class="line"></span><br><span class="line">	/* Number of cgroups in the hierarchy, used only for /proc/cgroups */</span><br><span class="line">	atomic_t nr_cgrps;</span><br><span class="line"></span><br><span class="line">	/* A list running through the active hierarchies */</span><br><span class="line">	struct list_head root_list;</span><br><span class="line"></span><br><span class="line">	/* Hierarchy-specific flags */</span><br><span class="line">	unsigned int flags;</span><br><span class="line"></span><br><span class="line">	/* The path to use for release notifications. */</span><br><span class="line">	char release_agent_path[PATH_MAX];</span><br><span class="line"></span><br><span class="line">	/* The name for this hierarchy - may be empty */</span><br><span class="line">	char name[MAX_CGROUP_ROOT_NAMELEN];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>But in the cgroup v2, all the subsystems are bind to one cgroup_root because it is only one mountpoint and normally using the default cgroup root:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">static int cgroup_get_tree(struct fs_context *fc)</span><br><span class="line">&#123;</span><br><span class="line">	struct cgroup_fs_context *ctx = cgroup_fc2context(fc);</span><br><span class="line">	int ret;</span><br><span class="line"></span><br><span class="line">	WRITE_ONCE(cgrp_dfl_visible, true);</span><br><span class="line">	cgroup_get_live(&amp;cgrp_dfl_root.cgrp);</span><br><span class="line">	ctx-&gt;root = &amp;cgrp_dfl_root;</span><br><span class="line"></span><br><span class="line">	ret = cgroup_do_get_tree(fc);</span><br><span class="line">	if (!ret)</span><br><span class="line">		apply_cgroup_root_flags(ctx-&gt;flags);</span><br><span class="line">	return ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* the default hierarchy */</span><br><span class="line">struct cgroup_root cgrp_dfl_root = &#123; .cgrp.rstat_cpu = &amp;cgrp_dfl_root_rstat_cpu &#125;;</span><br><span class="line">EXPORT_SYMBOL_GPL(cgrp_dfl_root);</span><br></pre></td></tr></table></figure>


<p>The default cgroup has all subsys_mask. All the child cgroup from the root cgroup will bind the subsystem cgroup by enabling it in the parent cgroup’s cgroup.subtree_control. So the different subsystems can have easier cooperation with each other.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int __init cgroup_init(void)</span><br><span class="line">&#123;</span><br><span class="line">	for_each_subsys(ss, ssid) &#123;</span><br><span class="line">		list_add_tail(&amp;init_css_set.e_cset_node[ssid],</span><br><span class="line">			      &amp;cgrp_dfl_root.cgrp.e_csets[ssid]);</span><br><span class="line"></span><br><span class="line">		cgrp_dfl_root.subsys_mask |= 1 &lt;&lt; ss-&gt;id;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="How-kernel-implement-the-cgroup-v2-writeback"><a href="#How-kernel-implement-the-cgroup-v2-writeback" class="headerlink" title="How kernel implement the cgroup v2 writeback"></a>How kernel implement the cgroup v2 writeback</h3><p>After the kernel added a unified cgroup hierarchy, another patch <a target="_blank" rel="noopener" href="https://lwn.net/Articles/628631/">writeback: cgroup writeback support</a> merged in January, 2015. It adds a feature and framework to support the writeback control by cgroup. Then the ext4 filesystem added the support with writeback cgroup <a target="_blank" rel="noopener" href="https://lwn.net/Articles/648299/">ext4: implement cgroup writeback support</a> at Jun, 2015. But xfs filesystem implements the support at <a target="_blank" rel="noopener" href="https://patchwork.kernel.org/project/xfs/patch/f13839700d372a4663a08a11883e9c89b13056ca.1521752282.git.shli@fb.com/">[V2] xfs: implement cgroup writeback support</a> on March, 2018. So on some old kernel versions, the xfs filesystem does not support cgroup writeback. </p>
<p>Now let’s do the deep dive about how the kernel implements the cgroup writeback. The implementation of cgroup writeback is complex with many different packages and adds many new changes after the original patch. Here we just analyze and focus on the latest kernel version and skip the history and change from the first patch.</p>
<p>There is full flow of write:</p>
<p><img src="/images/cgroupv2_full_flow.png" alt="cgroupv2_full_flow"></p>
<p>As the write as example, there is the simplify flow from syscall of write to enter of block layer:</p>
<p><img src="/images/cgroupv2_simple_flow.png" alt="cgroupv2_simple_flow"></p>
<p>When calling the write syscall with buffer io, vfs calls the generic_perform_write function and runs the interface write_begin and write_end in proper order. Between them, the raw_copy_from_user is the real data write from the user space into the kernel space of the memory area. In the write_end stage, mark_buffer_dirty function marks the memory page and inode is dirty and wait to writeout: </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">void mark_buffer_dirty(struct buffer_head *bh)</span><br><span class="line">&#123;</span><br><span class="line">	WARN_ON_ONCE(!buffer_uptodate(bh));</span><br><span class="line"></span><br><span class="line">	trace_block_dirty_buffer(bh);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Very *carefully* optimize the it-is-already-dirty case.</span><br><span class="line">	 *</span><br><span class="line">	 * Don&#x27;t let the final &quot;is it dirty&quot; escape to before we</span><br><span class="line">	 * perhaps modified the buffer.</span><br><span class="line">	 */</span><br><span class="line">	if (buffer_dirty(bh)) &#123;</span><br><span class="line">		smp_mb();</span><br><span class="line">		if (buffer_dirty(bh))</span><br><span class="line">			return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!test_set_buffer_dirty(bh)) &#123;</span><br><span class="line">		struct folio *folio = bh-&gt;b_folio;</span><br><span class="line">		struct address_space *mapping = NULL;</span><br><span class="line"></span><br><span class="line">		folio_memcg_lock(folio);</span><br><span class="line">		if (!folio_test_set_dirty(folio)) &#123;</span><br><span class="line">			mapping = folio-&gt;mapping;</span><br><span class="line">			if (mapping)</span><br><span class="line">				__folio_mark_dirty(folio, mapping, 0);</span><br><span class="line">		&#125;</span><br><span class="line">		folio_memcg_unlock(folio);</span><br><span class="line">		if (mapping)</span><br><span class="line">			__mark_inode_dirty(mapping-&gt;host, I_DIRTY_PAGES);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>The __mark_inode_dirty function calls the __inode_attach_wb to create a bdi_writeback structure and attach the inode into it. The cgwb_create function creates a bdi_writeback for this memory cgroup and adds it into the bdi-&gt;cgwb_tree and by wb_get_lookup to get the bdi_writeback.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">void __inode_attach_wb(struct inode *inode, struct folio *folio)</span><br><span class="line">&#123;</span><br><span class="line">	struct backing_dev_info *bdi = inode_to_bdi(inode);</span><br><span class="line">	struct bdi_writeback *wb = NULL;</span><br><span class="line"></span><br><span class="line">	if (inode_cgwb_enabled(inode)) &#123;</span><br><span class="line">		struct cgroup_subsys_state *memcg_css;</span><br><span class="line"></span><br><span class="line">		if (folio) &#123;</span><br><span class="line">			memcg_css = mem_cgroup_css_from_folio(folio);</span><br><span class="line">			wb = wb_get_create(bdi, memcg_css, GFP_ATOMIC);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			/* must pin memcg_css, see wb_get_create() */</span><br><span class="line">			memcg_css = task_get_css(current, memory_cgrp_id);</span><br><span class="line">			wb = wb_get_create(bdi, memcg_css, GFP_ATOMIC);</span><br><span class="line">			css_put(memcg_css);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (!wb)</span><br><span class="line">		wb = &amp;bdi-&gt;wb;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * There may be multiple instances of this function racing to</span><br><span class="line">	 * update the same inode.  Use cmpxchg() to tell the winner.</span><br><span class="line">	 */</span><br><span class="line">	if (unlikely(cmpxchg(&amp;inode-&gt;i_wb, NULL, wb)))</span><br><span class="line">		wb_put(wb);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//  wb_get_create - get wb for a given memcg, create if necessary</span><br><span class="line">struct bdi_writeback *wb_get_create(struct backing_dev_info *bdi,</span><br><span class="line">				    struct cgroup_subsys_state *memcg_css,</span><br><span class="line">				    gfp_t gfp)</span><br><span class="line">&#123;</span><br><span class="line">	struct bdi_writeback *wb;</span><br><span class="line"></span><br><span class="line">	might_alloc(gfp);</span><br><span class="line"></span><br><span class="line">	if (!memcg_css-&gt;parent)</span><br><span class="line">		return &amp;bdi-&gt;wb;</span><br><span class="line"></span><br><span class="line">	do &#123;</span><br><span class="line">		wb = wb_get_lookup(bdi, memcg_css);</span><br><span class="line">	&#125; while (!wb &amp;&amp; !cgwb_create(bdi, memcg_css, gfp));</span><br><span class="line"></span><br><span class="line">	return wb;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>The cgwb_create function is important, because it get the IO subsystem blkcg_css according to the memory cgroup by cgroup_get_e_css. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">static int cgwb_create(struct backing_dev_info *bdi,</span><br><span class="line">		       struct cgroup_subsys_state *memcg_css, gfp_t gfp)</span><br><span class="line">&#123;</span><br><span class="line">	struct mem_cgroup *memcg;</span><br><span class="line">	struct cgroup_subsys_state *blkcg_css;</span><br><span class="line">	struct list_head *memcg_cgwb_list, *blkcg_cgwb_list;</span><br><span class="line">	struct bdi_writeback *wb;</span><br><span class="line">	unsigned long flags;</span><br><span class="line">	int ret = 0;</span><br><span class="line"></span><br><span class="line">	memcg = mem_cgroup_from_css(memcg_css);</span><br><span class="line">	blkcg_css = cgroup_get_e_css(memcg_css-&gt;cgroup, &amp;io_cgrp_subsys);</span><br><span class="line">	memcg_cgwb_list = &amp;memcg-&gt;cgwb_list;</span><br><span class="line">	blkcg_cgwb_list = blkcg_get_cgwb_list(blkcg_css);</span><br><span class="line">            …</span><br><span class="line">	ret = wb_init(wb, bdi, gfp);</span><br><span class="line">	wb-&gt;memcg_css = memcg_css;</span><br><span class="line">	wb-&gt;blkcg_css = blkcg_css;</span><br><span class="line">           …</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>For the cgroup v2, the cgroup_get_e_css gets the IO css from the cgroup because all the subsystems bind to the cgroup. But for the cgroup v1, only the subsystem currently binds to the cgroup, so the cgroup_css returns NULL and goes back to the parent cgroup and finally gets the empty cgroup and breaks the loop. Then return the init IO css. But this css doesn’t contain the process and cgroup information. I think it is just for compatibility with cgroup v1 to return the init css.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">// cgroup_get_e_css - get a cgroup&#x27;s effective css for the specified subsystem</span><br><span class="line">struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgrp,</span><br><span class="line">					     struct cgroup_subsys *ss)</span><br><span class="line">&#123;</span><br><span class="line">	struct cgroup_subsys_state *css;</span><br><span class="line"></span><br><span class="line">	if (!CGROUP_HAS_SUBSYS_CONFIG)</span><br><span class="line">		return NULL;</span><br><span class="line"></span><br><span class="line">	rcu_read_lock();</span><br><span class="line"></span><br><span class="line">	do &#123;</span><br><span class="line">		css = cgroup_css(cgrp, ss);</span><br><span class="line"></span><br><span class="line">		if (css &amp;&amp; css_tryget_online(css))</span><br><span class="line">			goto out_unlock;</span><br><span class="line">		cgrp = cgroup_parent(cgrp);</span><br><span class="line">	&#125; while (cgrp);</span><br><span class="line"></span><br><span class="line">	css = init_css_set.subsys[ss-&gt;id];</span><br><span class="line">	css_get(css);</span><br><span class="line">out_unlock:</span><br><span class="line">	rcu_read_unlock();</span><br><span class="line">	return css;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Besides binding the cgroup, bdi and inode, the bdi_writeback needs to attach a real worker function to flush the diary page out to disk. This step at wb_init:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INIT_DELAYED_WORK(&amp;wb-&gt;dwork, wb_workfn);</span><br><span class="line">INIT_DELAYED_WORK(&amp;wb-&gt;bw_dwork, wb_update_bandwidth_workfn);</span><br></pre></td></tr></table></figure>


<p>The __mark_inode_dirty adds this work into the delayed work queue for the idle worker to do the flush work. The wb_update_bandwidth_workfn according to the writeback IO time, dirty writeback numbers and the completion writeback numbers to calculate the bandwidth of the writeback and update the dirty_ratelimit. There are some algorithms but not the point in this topic, just skip them.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">	static void __wb_update_bandwidth(struct dirty_throttle_control *gdtc,</span><br><span class="line">				  struct dirty_throttle_control *mdtc,</span><br><span class="line">				  bool update_ratelimit)</span><br><span class="line">&#123;</span><br><span class="line">            /*</span><br><span class="line">	 * Lockless checks for elapsed time are racy and delayed update after</span><br><span class="line">	 * IO completion doesn&#x27;t do it at all (to make sure written pages are</span><br><span class="line">	 * accounted reasonably quickly). Make sure elapsed &gt;= 1 to avoid</span><br><span class="line">	 * division errors.</span><br><span class="line">	 */</span><br><span class="line">	elapsed = max(now - wb-&gt;bw_time_stamp, 1UL);</span><br><span class="line">	dirtied = percpu_counter_read(&amp;wb-&gt;stat[WB_DIRTIED]);</span><br><span class="line">	written = percpu_counter_read(&amp;wb-&gt;stat[WB_WRITTEN]);</span><br><span class="line">           …</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Maintain wb-&gt;dirty_ratelimit, the base dirty throttle rate.</span><br><span class="line"> *</span><br><span class="line"> * Normal wb tasks will be curbed at or below it in long term.</span><br><span class="line"> * Obviously it should be around (write_bw / N) when there are N dd tasks.</span><br><span class="line"> */</span><br><span class="line">static void wb_update_dirty_ratelimit(struct dirty_throttle_control *dtc,</span><br><span class="line">				      unsigned long dirtied,</span><br><span class="line">				      unsigned long elapsed)</span><br><span class="line">&#123;</span><br><span class="line">	balanced_dirty_ratelimit = div_u64((u64)task_ratelimit * write_bw,</span><br><span class="line">					   dirty_rate | 1);</span><br><span class="line">	WRITE_ONCE(wb-&gt;dirty_ratelimit, max(dirty_ratelimit, 1UL));</span><br><span class="line">	wb-&gt;balanced_dirty_ratelimit = balanced_dirty_ratelimit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Now the wb has been prepared, it links to the real worker waiting to write out. It links to the inode, bdi, memory cgroup and IO cgoup. They can provide the information when writing out.</p>
<p>The wb_workfn function runs the __writeback_single_inode and calls the interface of writepages or writepage.  The different file system and backend implement the interfaces. But they have a similar process including wbc_init_bio and wbc_account_cgroup_owner before submitting the bio. </p>
<p><img src="/images/cgroupv2_simple_flow2.png" alt="cgroupv2_simple_flow2"></p>
<p>These two functions are patches added to the xfs and ext4 cgroup writeback support. We can see the cgroup v2 documentation about <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">Filesystem Support for Writeback</a>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Filesystem Support for Writeback</span><br><span class="line">--------------------------------</span><br><span class="line"></span><br><span class="line">A filesystem can support cgroup writeback by updating</span><br><span class="line">address_space_operations-&gt;writepage[s]() to annotate bio&#x27;s using the</span><br><span class="line">following two functions.</span><br><span class="line"></span><br><span class="line">  wbc_init_bio(@wbc, @bio)</span><br><span class="line">	Should be called for each bio carrying writeback data and</span><br><span class="line">	associates the bio with the inode&#x27;s owner cgroup and the</span><br><span class="line">	corresponding request queue.  This must be called after</span><br><span class="line">	a queue (device) has been associated with the bio and</span><br><span class="line">	before submission.</span><br><span class="line"></span><br><span class="line">  wbc_account_cgroup_owner(@wbc, @page, @bytes)</span><br><span class="line">	Should be called for each data segment being written out.</span><br><span class="line">	While this function doesn&#x27;t care exactly when it&#x27;s called</span><br><span class="line">	during the writeback session, it&#x27;s the easiest and most</span><br><span class="line">	natural to call it as data segments are added to a bio.</span><br></pre></td></tr></table></figure>


<p>The wbc is writeback_control which manages and controls total writeback flow and stores the bdi_writeback and inode. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * A control structure which tells the writeback code what to do.  These are</span><br><span class="line"> * always on the stack, and hence need no locking.  They are always initialised</span><br><span class="line"> * in a manner such that unspecified fields are set to zero.</span><br><span class="line"> */</span><br><span class="line">struct writeback_control &#123;</span><br><span class="line">	long nr_to_write;		/* Write this many pages, and decrement</span><br><span class="line">					   this for each page written */</span><br><span class="line">            …</span><br><span class="line">#ifdef CONFIG_CGROUP_WRITEBACK</span><br><span class="line">	struct bdi_writeback *wb;	/* wb this writeback is issued under */</span><br><span class="line">	struct inode *inode;		/* inode being written out */</span><br><span class="line">#endif</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>wbc_init_bio() binds the specified bio to its cgroup which binds at cgwb_create function.  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">static inline void wbc_init_bio(struct writeback_control *wbc, struct bio *bio)</span><br><span class="line">&#123;</span><br><span class="line">	/*</span><br><span class="line">	 * pageout() path doesn&#x27;t attach @wbc to the inode being written</span><br><span class="line">	 * out.  This is intentional as we don&#x27;t want the function to block</span><br><span class="line">	 * behind a slow cgroup.  Ultimately, we want pageout() to kick off</span><br><span class="line">	 * regular writeback instead of writing things out itself.</span><br><span class="line">	 */</span><br><span class="line">	if (wbc-&gt;wb)</span><br><span class="line">		bio_associate_blkg_from_css(bio, wbc-&gt;wb-&gt;blkcg_css);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//  bio_associate_blkg_from_css - associate a bio with a specified css</span><br><span class="line">void bio_associate_blkg_from_css(struct bio *bio,</span><br><span class="line">				 struct cgroup_subsys_state *css)</span><br><span class="line">&#123;</span><br><span class="line">	if (bio-&gt;bi_blkg)</span><br><span class="line">		blkg_put(bio-&gt;bi_blkg);</span><br><span class="line"></span><br><span class="line">	if (css &amp;&amp; css-&gt;parent) &#123;</span><br><span class="line">		bio-&gt;bi_blkg = blkg_tryget_closest(bio, css);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		blkg_get(bdev_get_queue(bio-&gt;bi_bdev)-&gt;root_blkg);</span><br><span class="line">		bio-&gt;bi_blkg = bdev_get_queue(bio-&gt;bi_bdev)-&gt;root_blkg;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Here the bio binds to the IO cgroup on bi_blkg, if the css is empty, it will bind to the root cgroup.</p>
<p>The wbc_account_cgroup_owner is a solution for this question: if multiple processes from different cgroup write into the same inode, how to decide who is the owner of this inode right now. The wbc_account_cgroup_owner counts the pages to different cgroup by memory id. After finishing the current writeback, the wbc_detach_inode function uses Boyer-Moore majority vote algorithm to select the owner of this inode, then calls inode_switch_wbs to switch the bdi_writeback for the inode.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">//  wbc_account_cgroup_owner - account writeback to update inode cgroup ownership</span><br><span class="line">void wbc_account_cgroup_owner(struct writeback_control *wbc, struct page *page,</span><br><span class="line">			      size_t bytes)</span><br><span class="line">&#123;</span><br><span class="line">	struct folio *folio;</span><br><span class="line">	struct cgroup_subsys_state *css;</span><br><span class="line">	int id;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * pageout() path doesn&#x27;t attach @wbc to the inode being written</span><br><span class="line">	 * out.  This is intentional as we don&#x27;t want the function to block</span><br><span class="line">	 * behind a slow cgroup.  Ultimately, we want pageout() to kick off</span><br><span class="line">	 * regular writeback instead of writing things out itself.</span><br><span class="line">	 */</span><br><span class="line">	if (!wbc-&gt;wb || wbc-&gt;no_cgroup_owner)</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	folio = page_folio(page);</span><br><span class="line">	css = mem_cgroup_css_from_folio(folio);</span><br><span class="line">	/* dead cgroups shouldn&#x27;t contribute to inode ownership arbitration */</span><br><span class="line">	if (!(css-&gt;flags &amp; CSS_ONLINE))</span><br><span class="line">		return;</span><br><span class="line"></span><br><span class="line">	id = css-&gt;id;</span><br><span class="line"></span><br><span class="line">	if (id == wbc-&gt;wb_id) &#123;</span><br><span class="line">		wbc-&gt;wb_bytes += bytes;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if (id == wbc-&gt;wb_lcand_id)</span><br><span class="line">		wbc-&gt;wb_lcand_bytes += bytes;</span><br><span class="line"></span><br><span class="line">	/* Boyer-Moore majority vote algorithm */</span><br><span class="line">	if (!wbc-&gt;wb_tcand_bytes)</span><br><span class="line">		wbc-&gt;wb_tcand_id = id;</span><br><span class="line">	if (id == wbc-&gt;wb_tcand_id)</span><br><span class="line">		wbc-&gt;wb_tcand_bytes += bytes;</span><br><span class="line">	else</span><br><span class="line">		wbc-&gt;wb_tcand_bytes -= min(bytes, wbc-&gt;wb_tcand_bytes);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * mem_cgroup_css_from_folio - css of the memcg associated with a folio</span><br><span class="line"> * @folio: folio of interest</span><br><span class="line"> *</span><br><span class="line"> * If memcg is bound to the default hierarchy, css of the memcg associated</span><br><span class="line"> * with @folio is returned.  The returned css remains associated with @folio</span><br><span class="line"> * until it is released.</span><br><span class="line"> *</span><br><span class="line"> * If memcg is bound to a traditional hierarchy, the css of root_mem_cgroup</span><br><span class="line"> * is returned.</span><br><span class="line"> */</span><br><span class="line">struct cgroup_subsys_state *mem_cgroup_css_from_folio(struct folio *folio)</span><br><span class="line">&#123;</span><br><span class="line">	struct mem_cgroup *memcg = folio_memcg(folio);</span><br><span class="line"></span><br><span class="line">	if (!memcg || !cgroup_subsys_on_dfl(memory_cgrp_subsys))</span><br><span class="line">		memcg = root_mem_cgroup;</span><br><span class="line"></span><br><span class="line">	return &amp;memcg-&gt;css;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>The cgroup v1 returns the root cgroup as well because it can not handle this case.</p>
<p>So in cgroup v2, before entering the block layer, the filesystem layer has decided which IO cgroup binds to this bio according to the inode and memory cgroup. The bio contains the io cgroup and then it is transferred to direct IO after calling submit_bio. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">struct bio &#123;</span><br><span class="line">…</span><br><span class="line">#ifdef CONFIG_BLK_CGROUP</span><br><span class="line">	/*</span><br><span class="line">	 * Represents the association of the css and request_queue for the bio.</span><br><span class="line">	 * If a bio goes direct to device, it will not have a blkg as it will</span><br><span class="line">	 * not have a request_queue associated with it.  The reference is put</span><br><span class="line">	 * on release of the bio.</span><br><span class="line">	 */</span><br><span class="line">	struct blkcg_gq		*bi_blkg;</span><br><span class="line">	struct bio_issue	bi_issue;</span><br><span class="line">…</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="How-IO-throttling-in-block-layer"><a href="#How-IO-throttling-in-block-layer" class="headerlink" title="How IO throttling in block layer"></a>How IO throttling in block layer</h3><p>There are the different throttling files with cgroup v1 and v2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">static struct cftype throtl_legacy_files[] = &#123;</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.read_bps_device&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, bps[READ][LIMIT_MAX]),</span><br><span class="line">		.seq_show = tg_print_conf_u64,</span><br><span class="line">		.write = tg_set_conf_u64,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.write_bps_device&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, bps[WRITE][LIMIT_MAX]),</span><br><span class="line">		.seq_show = tg_print_conf_u64,</span><br><span class="line">		.write = tg_set_conf_u64,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.read_iops_device&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, iops[READ][LIMIT_MAX]),</span><br><span class="line">		.seq_show = tg_print_conf_uint,</span><br><span class="line">		.write = tg_set_conf_uint,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.write_iops_device&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, iops[WRITE][LIMIT_MAX]),</span><br><span class="line">		.seq_show = tg_print_conf_uint,</span><br><span class="line">		.write = tg_set_conf_uint,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.io_service_bytes&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, stat_bytes),</span><br><span class="line">		.seq_show = tg_print_rwstat,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.io_service_bytes_recursive&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, stat_bytes),</span><br><span class="line">		.seq_show = tg_print_rwstat_recursive,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.io_serviced&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, stat_ios),</span><br><span class="line">		.seq_show = tg_print_rwstat,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;throttle.io_serviced_recursive&quot;,</span><br><span class="line">		.private = offsetof(struct throtl_grp, stat_ios),</span><br><span class="line">		.seq_show = tg_print_rwstat_recursive,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123; &#125;	/* terminate */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">static struct cftype throtl_files[] = &#123;</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;max&quot;,</span><br><span class="line">		.flags = CFTYPE_NOT_ON_ROOT,</span><br><span class="line">		.seq_show = tg_print_limit,</span><br><span class="line">		.write = tg_set_limit,</span><br><span class="line">		.private = LIMIT_MAX,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123; &#125;	/* terminate */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


<p>In cgroup v2 we only need to set all the disk IO limitations like read&#x2F;write bps and iops on io.max file. Once we set the io.max, all the blk cgroup configs are set to the throtl_grp structure by  tg_set_limit. Here the doc focusing on the cgroup v2 implementation. </p>
<p>When registering the blk throttle to the disk, it sets the throtl_slice according to different disk types. That is the default window of calculating the throttling IO.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void blk_throtl_register(struct gendisk *disk)</span><br><span class="line">&#123;</span><br><span class="line">	struct request_queue *q = disk-&gt;queue;</span><br><span class="line">	struct throtl_data *td;</span><br><span class="line">	int i;</span><br><span class="line"></span><br><span class="line">	td = q-&gt;td;</span><br><span class="line">	BUG_ON(!td);</span><br><span class="line"></span><br><span class="line">	if (blk_queue_nonrot(q)) &#123;</span><br><span class="line">		td-&gt;throtl_slice = DFL_THROTL_SLICE_SSD;</span><br><span class="line">		td-&gt;filtered_latency = LATENCY_FILTERED_SSD;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		td-&gt;throtl_slice = DFL_THROTL_SLICE_HD;</span><br><span class="line">		td-&gt;filtered_latency = LATENCY_FILTERED_HD;</span><br><span class="line">           &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>Following the tg_set_limit function, the tg_conf_updated is important function to update the throtl_grp and calculate the wait time and dispatch time of the bio.  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">static void tg_conf_updated(struct throtl_grp *tg, bool global)</span><br><span class="line">&#123;</span><br><span class="line">	struct throtl_service_queue *sq = &amp;tg-&gt;service_queue;</span><br><span class="line">	struct cgroup_subsys_state *pos_css;</span><br><span class="line">	struct blkcg_gq *blkg;</span><br><span class="line"></span><br><span class="line">	throtl_log(&amp;tg-&gt;service_queue,</span><br><span class="line">		   &quot;limit change rbps=%llu wbps=%llu riops=%u wiops=%u&quot;,</span><br><span class="line">		   tg_bps_limit(tg, READ), tg_bps_limit(tg, WRITE),</span><br><span class="line">		   tg_iops_limit(tg, READ), tg_iops_limit(tg, WRITE));</span><br><span class="line"></span><br><span class="line">	blkg_for_each_descendant_pre(blkg, pos_css,</span><br><span class="line">			global ? tg-&gt;td-&gt;queue-&gt;root_blkg : tg_to_blkg(tg)) &#123;</span><br><span class="line">		struct throtl_grp *this_tg = blkg_to_tg(blkg);</span><br><span class="line">		struct throtl_grp *parent_tg;</span><br><span class="line"></span><br><span class="line">		tg_update_has_rules(this_tg);</span><br><span class="line">		/* ignore root/second level */</span><br><span class="line">		if (!cgroup_subsys_on_dfl(io_cgrp_subsys) || !blkg-&gt;parent ||</span><br><span class="line">		    !blkg-&gt;parent-&gt;parent)</span><br><span class="line">			continue;</span><br><span class="line">		parent_tg = blkg_to_tg(blkg-&gt;parent);</span><br><span class="line">		/*</span><br><span class="line">		 * make sure all children has lower idle time threshold and</span><br><span class="line">		 * higher latency target</span><br><span class="line">		 */</span><br><span class="line">		this_tg-&gt;idletime_threshold = min(this_tg-&gt;idletime_threshold,</span><br><span class="line">				parent_tg-&gt;idletime_threshold);</span><br><span class="line">		this_tg-&gt;latency_target = max(this_tg-&gt;latency_target,</span><br><span class="line">				parent_tg-&gt;latency_target);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We&#x27;re already holding queue_lock and know @tg is valid.  Let&#x27;s</span><br><span class="line">	 * apply the new config directly.</span><br><span class="line">	 *</span><br><span class="line">	 * Restart the slices for both READ and WRITES. It might happen</span><br><span class="line">	 * that a group&#x27;s limit are dropped suddenly and we don&#x27;t want to</span><br><span class="line">	 * account recently dispatched IO with new low rate.</span><br><span class="line">	 */</span><br><span class="line">	throtl_start_new_slice(tg, READ, false);</span><br><span class="line">	throtl_start_new_slice(tg, WRITE, false);</span><br><span class="line"></span><br><span class="line">	if (tg-&gt;flags &amp; THROTL_TG_PENDING) &#123;</span><br><span class="line">		tg_update_disptime(tg);</span><br><span class="line">		throtl_schedule_next_dispatch(sq-&gt;parent_sq, true);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">static void tg_update_disptime(struct throtl_grp *tg)</span><br><span class="line">&#123;</span><br><span class="line">	struct throtl_service_queue *sq = &amp;tg-&gt;service_queue;</span><br><span class="line">	unsigned long read_wait = -1, write_wait = -1, min_wait = -1, disptime;</span><br><span class="line">	struct bio *bio;</span><br><span class="line"></span><br><span class="line">	bio = throtl_peek_queued(&amp;sq-&gt;queued[READ]);</span><br><span class="line">	if (bio)</span><br><span class="line">		tg_may_dispatch(tg, bio, &amp;read_wait);</span><br><span class="line"></span><br><span class="line">	bio = throtl_peek_queued(&amp;sq-&gt;queued[WRITE]);</span><br><span class="line">	if (bio)</span><br><span class="line">		tg_may_dispatch(tg, bio, &amp;write_wait);</span><br><span class="line"></span><br><span class="line">	min_wait = min(read_wait, write_wait);</span><br><span class="line">	disptime = jiffies + min_wait;</span><br><span class="line"></span><br><span class="line">	/* Update dispatch time */</span><br><span class="line">	throtl_rb_erase(&amp;tg-&gt;rb_node, tg-&gt;service_queue.parent_sq);</span><br><span class="line">	tg-&gt;disptime = disptime;</span><br><span class="line">	tg_service_queue_add(tg);</span><br><span class="line"></span><br><span class="line">	/* see throtl_add_bio_tg() */</span><br><span class="line">	tg-&gt;flags &amp;= ~THROTL_TG_WAS_EMPTY;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>The dispatch time use the minimum of the write wait time and read wait time calculated by the tg_may_dispatch. Then add the throtl_grp into the service queue wait to dispatch. Every update the io.max, the kernel need new window slice to throttling. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">static inline void throtl_start_new_slice(struct throtl_grp *tg, bool rw,</span><br><span class="line">					  bool clear_carryover)</span><br><span class="line">&#123;</span><br><span class="line">	tg-&gt;bytes_disp[rw] = 0;</span><br><span class="line">	tg-&gt;io_disp[rw] = 0;</span><br><span class="line">	tg-&gt;slice_start[rw] = jiffies;</span><br><span class="line">	tg-&gt;slice_end[rw] = jiffies + tg-&gt;td-&gt;throtl_slice;</span><br><span class="line">	if (clear_carryover) &#123;</span><br><span class="line">		tg-&gt;carryover_bytes[rw] = 0;</span><br><span class="line">		tg-&gt;carryover_ios[rw] = 0;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>The global variable <a target="_blank" rel="noopener" href="https://litux.nl/mirror/kerneldevelopment/0672327201/ch10lev1sec3.html">jiffies</a> holds the number of ticks that have occurred since the system booted. On boot, the kernel initializes the variable to zero, and it is incremented by one during each timer interrupt. Thus, because there are HZ timer interrupts in a second, there are HZ jiffies in a second. The system uptime is therefore jiffies&#x2F;HZ seconds.</p>
<p>It is similar for the disk IO to the cpu: dividing the disk resource into time according to the disk frequency. The “time” is not the real linear time but it is “jiffy” which the numbers of the tick from uptime. So the uptime &#x3D; jiffies &#x2F; HZ.</p>
<p>The core algorithm is that for every cgroup for this disk, kernel use sibling window (slice) to decide how much time the bio need to wait or just dispatch. It calculates the max bps or iops in this window. If the latest bio is exceed the numbers of the bps or iops, it extends the window and wait time of the window end. So it is not the fixed slice except the new slice of beginning. The details of the implement is in the tg_may_dispatch. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Returns whether one can dispatch a bio or not. Also returns approx number</span><br><span class="line"> * of jiffies to wait before this bio is with-in IO rate and can be dispatched</span><br><span class="line"> */</span><br><span class="line">static bool tg_may_dispatch(struct throtl_grp *tg, struct bio *bio,</span><br><span class="line">			    unsigned long *wait)</span><br><span class="line">&#123;</span><br><span class="line">	bool rw = bio_data_dir(bio);</span><br><span class="line">	unsigned long bps_wait = 0, iops_wait = 0, max_wait = 0;</span><br><span class="line">	u64 bps_limit = tg_bps_limit(tg, rw);</span><br><span class="line">	u32 iops_limit = tg_iops_limit(tg, rw);</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line"> 	 * Currently whole state machine of group depends on first bio</span><br><span class="line">	 * queued in the group bio list. So one should not be calling</span><br><span class="line">	 * this function with a different bio if there are other bios</span><br><span class="line">	 * queued.</span><br><span class="line">	 */</span><br><span class="line">	BUG_ON(tg-&gt;service_queue.nr_queued[rw] &amp;&amp;</span><br><span class="line">	       bio != throtl_peek_queued(&amp;tg-&gt;service_queue.queued[rw]));</span><br><span class="line"></span><br><span class="line">	/* If tg-&gt;bps = -1, then BW is unlimited */</span><br><span class="line">	if ((bps_limit == U64_MAX &amp;&amp; iops_limit == UINT_MAX) ||</span><br><span class="line">	    tg-&gt;flags &amp; THROTL_TG_CANCELING) &#123;</span><br><span class="line">		if (wait)</span><br><span class="line">			*wait = 0;</span><br><span class="line">		return true;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * If previous slice expired, start a new one otherwise renew/extend</span><br><span class="line">	 * existing slice to make sure it is at least throtl_slice interval</span><br><span class="line">	 * long since now. New slice is started only for empty throttle group.</span><br><span class="line">	 * If there is queued bio, that means there should be an active</span><br><span class="line">	 * slice and it should be extended instead.</span><br><span class="line">	 */</span><br><span class="line">	if (throtl_slice_used(tg, rw) &amp;&amp; !(tg-&gt;service_queue.nr_queued[rw]))</span><br><span class="line">		throtl_start_new_slice(tg, rw, true);</span><br><span class="line">	else &#123;</span><br><span class="line">		if (time_before(tg-&gt;slice_end[rw],</span><br><span class="line">		    jiffies + tg-&gt;td-&gt;throtl_slice))</span><br><span class="line">			throtl_extend_slice(tg, rw,</span><br><span class="line">				jiffies + tg-&gt;td-&gt;throtl_slice);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	bps_wait = tg_within_bps_limit(tg, bio, bps_limit);</span><br><span class="line">	iops_wait = tg_within_iops_limit(tg, bio, iops_limit);</span><br><span class="line">	if (bps_wait + iops_wait == 0) &#123;</span><br><span class="line">		if (wait)</span><br><span class="line">			*wait = 0;</span><br><span class="line">		return true;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	max_wait = max(bps_wait, iops_wait);</span><br><span class="line"></span><br><span class="line">	if (wait)</span><br><span class="line">		*wait = max_wait;</span><br><span class="line"></span><br><span class="line">	if (time_before(tg-&gt;slice_end[rw], jiffies + max_wait))</span><br><span class="line">		throtl_extend_slice(tg, rw, jiffies + max_wait);</span><br><span class="line"></span><br><span class="line">	return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>Now we look back to the bio follow and the blk_throtl_bio is between the A and Q. </p>
<p><img src="/images/throttling.png" alt="images/throttling"></p>
<p>If set to io.max, every bio goes through the _blk_throtl_bio and runs tg_may_dispatch to check whether the bio can be dispatched directly or not. If not, calculate the wait time and update the timer with the minimum wait time from the rb_tree. Finally it adds the bio into the service queue and waits for the timer to run the next dispatch loop.</p>
<p><img src="/images/blk_throttling.png" alt="blk_throttleing"></p>
<h2 id="Disk-IO-QoS"><a href="#Disk-IO-QoS" class="headerlink" title="Disk IO QoS"></a>Disk IO QoS</h2><p>Both of them are controlled by the rq_qos structure:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">struct rq_qos &#123;</span><br><span class="line">	const struct rq_qos_ops *ops;</span><br><span class="line">	struct gendisk *disk;</span><br><span class="line">	enum rq_qos_id id;</span><br><span class="line">	struct rq_qos *next;</span><br><span class="line">#ifdef CONFIG_BLK_DEBUG_FS</span><br><span class="line">	struct dentry *debugfs_dir;</span><br><span class="line">#endif</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">struct rq_qos_ops &#123;</span><br><span class="line">	void (*throttle)(struct rq_qos *, struct bio *);</span><br><span class="line">	void (*track)(struct rq_qos *, struct request *, struct bio *);</span><br><span class="line">	void (*merge)(struct rq_qos *, struct request *, struct bio *);</span><br><span class="line">	void (*issue)(struct rq_qos *, struct request *);</span><br><span class="line">	void (*requeue)(struct rq_qos *, struct request *);</span><br><span class="line">	void (*done)(struct rq_qos *, struct request *);</span><br><span class="line">	void (*done_bio)(struct rq_qos *, struct bio *);</span><br><span class="line">	void (*cleanup)(struct rq_qos *, struct bio *);</span><br><span class="line">	void (*queue_depth_changed)(struct rq_qos *);</span><br><span class="line">	void (*exit)(struct rq_qos *);</span><br><span class="line">	const struct blk_mq_debugfs_attr *debugfs_attrs;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


<p>The rq_qos is the singly linked list. There are 3 rq_qos plugins that can be used: blk-iolatency, blk-iocost and blk-wbt.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">static struct cftype iolatency_files[] = &#123;</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;latency&quot;,</span><br><span class="line">		.flags = CFTYPE_NOT_ON_ROOT,</span><br><span class="line">		.seq_show = iolatency_print_limit,</span><br><span class="line">		.write = iolatency_set_limit,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">static struct cftype ioc_files[] = &#123;</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;weight&quot;,</span><br><span class="line">		.flags = CFTYPE_NOT_ON_ROOT,</span><br><span class="line">		.seq_show = ioc_weight_show,</span><br><span class="line">		.write = ioc_weight_write,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;cost.qos&quot;,</span><br><span class="line">		.flags = CFTYPE_ONLY_ON_ROOT,</span><br><span class="line">		.seq_show = ioc_qos_show,</span><br><span class="line">		.write = ioc_qos_write,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;</span><br><span class="line">		.name = &quot;cost.model&quot;,</span><br><span class="line">		.flags = CFTYPE_ONLY_ON_ROOT,</span><br><span class="line">		.seq_show = ioc_cost_model_show,</span><br><span class="line">		.write = ioc_cost_model_write,</span><br><span class="line">	&#125;,</span><br><span class="line">	&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


<p>We have learned the block layer basic follow and we can know the place of rq_qos throttling. </p>
<p><img src="/images/disk_qos_1.png" alt="alt_text"></p>
<p>IO QoS has complicated algorithms for different policy and implementation. Here is just making an entrance but not deep diving. I will make another article to talk about the disk IO QoS.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/04/2024-05-06-CSI-INLINE-VOLUME-BECOME-ORPHAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/04/2024-05-06-CSI-INLINE-VOLUME-BECOME-ORPHAN/" class="post-title-link" itemprop="url">CSI Inline Volume Become Orphan After Kubelet Restart When Pod Terminating</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-04 13:32:27" itemprop="dateCreated datePublished" datetime="2024-04-04T13:32:27+08:00">2024-04-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-06 17:14:38" itemprop="dateModified" datetime="2024-05-06T17:14:38+08:00">2024-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cloud/" itemprop="url" rel="index"><span itemprop="name">cloud</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="CSI-Inline-Volume-Become-Orphan-After-Kubelet-Restart-When-Pod-Terminating"><a href="#CSI-Inline-Volume-Become-Orphan-After-Kubelet-Restart-When-Pod-Terminating" class="headerlink" title="CSI Inline Volume Become Orphan After Kubelet Restart When Pod Terminating"></a>CSI Inline Volume Become Orphan After Kubelet Restart When Pod Terminating</h2><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>When the pod is terminating and csi inline volume is deleted, the kubelet down or restart impact the volume become orphan and pod skip delete and unmount the volume. The error message show as follow:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Mar 12 00:28:56 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526549]: I0312 00:28:56.150307 1526549 state_mem.go:36] &quot;Initialized new in-memory state store&quot;</span><br><span class="line">Mar 12 00:28:56 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526549]: E0312 00:28:56.153369 1526549 server.go:302] &quot;Failed to run kubelet&quot; err=&quot;failed to run Kubelet: unable to determine runtime API version: rpc error: code = Unknown desc = server is not initialized yet&quot;</span><br><span class="line">Mar 12 00:28:56 tess-node-kltc4-tess19.stratus.lvs.ebay.com systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE</span><br><span class="line">Mar 12 00:28:56 tess-node-kltc4-tess19.stratus.lvs.ebay.com systemd[1]: kubelet.service: Failed with result &#x27;exit-code&#x27;.</span><br><span class="line">Mar 12 00:28:58 tess-node-kltc4-tess19.stratus.lvs.ebay.com systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.</span><br><span class="line">Mar 12 00:28:58 tess-node-kltc4-tess19.stratus.lvs.ebay.com systemd[1]: Stopped Kubernetes Kubelet Server.</span><br><span class="line">Mar 12 00:28:58 tess-node-kltc4-tess19.stratus.lvs.ebay.com systemd[1]: Started Kubernetes Kubelet Server.</span><br><span class="line">...</span><br><span class="line">Mar 12 00:29:01 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: I0312 00:29:01.976957 1526901 reconciler.go:388] &quot;Could not construct volume information, cleaning up mounts&quot; podName=1517b38e-fa84-4138-b6c0-06663741e385 volumeSpecName=&quot;data&quot; err=&quot;failed to GetVolumeName from volumePlugin for volumeSpec \&quot;data\&quot; err=kubernetes.io/csi: plugin.GetVolumeName failed to extract volume source from spec: unexpected api.CSIVolumeSource found in volume.Spec&quot;</span><br><span class="line">Mar 12 00:29:01 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: I0312 00:29:01.976982 1526901 reconciler.go:421] &quot;Reconciler sync states: could not find volume information in desired state, clean up the mount points&quot; podName=1517b38e-fa84-4138-b6c0-06663741e385 volumeSpecName=&quot;data&quot;</span><br><span class="line">Mar 12 00:29:01 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: E0312 00:29:01.981982 1526901 operation_generator.go:952] UnmountVolume.MarkVolumeMountAsUncertain failed for volume &quot;&quot; (UniqueName: &quot;data&quot;) pod &quot;1517b38e-fa84-4138-b6c0-06663741e385&quot; (UID: &quot;1517b38e-fa84-4138-b6c0-06663741e385&quot;) : no volume with the name &quot;data&quot; exists in the list of attached volumes</span><br><span class="line">Mar 12 00:29:01 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: E0312 00:29:01.982029 1526901 nestedpendingoperations.go:335] Operation for &quot;&#123;volumeName:data podName:1517b38e-fa84-4138-b6c0-06663741e385 nodeName:&#125;&quot; failed. No retries permitted until 2024-03-12 00:29:02.482017035 -0700 -07 m=+1.794257422 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume &quot;&quot; (UniqueName: &quot;data&quot;) pod &quot;1517b38e-fa84-4138-b6c0-06663741e385&quot; (UID: &quot;1517b38e-fa84-4138-b6c0-06663741e385&quot;) : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Aborted desc = NodeUnpublish operation for volume csi-c6b0a910c881c66f817829d6c0815f60d2dee9c028369214c6f1224be8139978 still ongoing</span><br><span class="line">Mar 12 00:29:44 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: I0312 00:29:44.655173 1526901 kubelet.go:2126] &quot;SyncLoop DELETE&quot; source=&quot;api&quot; pods=[kube-system/fio-test-6b7df68464-r66bv]</span><br><span class="line">Mar 12 00:29:44 tess-node-kltc4-tess19.stratus.lvs.ebay.com kubelet[1526901]: I0312 00:29:44.658223 1526901 kubelet.go:2120] &quot;SyncLoop REMOVE&quot; source=&quot;api&quot; pods=[kube-system/fio-test-6b7df68464-r66bv]</span><br></pre></td></tr></table></figure>


<p>From the error messages, we can know what happened:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Kubelet restart </span><br><span class="line">  -&gt; reconstructVolume </span><br><span class="line">     -&gt; get csi volume plugin by FindAttachablePluginByName and FindDeviceMountablePluginByName </span><br><span class="line">        -&gt; util.GetUniqueVolumeNameFromSpec </span><br><span class="line">          -&gt; volumePlugin.GetVolumeName </span><br><span class="line">             -&gt; getPVSourceFromSpec </span><br><span class="line">                -&gt; get error &quot;unexpected api.CSIVolumeSource found in volume.Spec&quot; because this function only check CSIPersistentVolumeSource</span><br></pre></td></tr></table></figure>


<p>When reconstructVolume gets an error, the volume can not be added into the ActualStateOfWorld in kubelet, then the kubelet will skip this volume unmount when pod deleting.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">reconstructedVolume, err := rc.reconstructVolume(volume)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		if volumeInDSW &#123;</span><br><span class="line">			// Some pod needs the volume, don&#x27;t clean it up and hope that</span><br><span class="line">			// reconcile() calls SetUp and reconstructs the volume in ASW.</span><br><span class="line">			klog.V(4).InfoS(&quot;Volume exists in desired state, skip cleaning up mounts&quot;, &quot;podName&quot;, volume.podName, &quot;volumeSpecName&quot;, volume.volumeSpecName)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line">		// No pod needs the volume.</span><br><span class="line">		klog.InfoS(&quot;Could not construct volume information, cleaning up mounts&quot;, &quot;podName&quot;, volume.podName, &quot;volumeSpecName&quot;, volume.volumeSpecName, &quot;err&quot;, err)</span><br><span class="line">		rc.cleanupMounts(volume)</span><br><span class="line">		continue</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>So there is a bug that the csi ephemeral volume should go into <strong>‘GetUniqueVolumeNameFromSpecWithPod’</strong> not **‘GetUniqueVolumeNameFromSpec’. **That means csi ephemeral volume <strong>should not</strong> get the attachablePlugin and deviceMountablePlugin.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if attachablePlugin != nil || deviceMountablePlugin != nil &#123;</span><br><span class="line">	uniqueVolumeName, err = util.GetUniqueVolumeNameFromSpec(plugin, volumeSpec)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">	uniqueVolumeName = util.GetUniqueVolumeNameFromSpecWithPod(volume.podName, plugin, volumeSpec)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>This place should use <code>_FindDeviceMountablePluginBySpec_</code> not <code>_FindAttachablePluginByName_</code> to get the volume plugin:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">attachablePlugin, err := rc.volumePluginMgr.FindAttachablePluginByName(volume.pluginName)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">	return nil, err</span><br><span class="line">&#125;</span><br><span class="line">deviceMountablePlugin, err := rc.volumePluginMgr.FindDeviceMountablePluginByName(volume.pluginName)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">	return nil, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>Actually, due to pod is terminating and pod not added into the DSW, when reconstructVolume failed, the kubelet still try to unmount and clean mountpoint for this volume:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">func (dswp *desiredStateOfWorldPopulator) findAndAddNewPods() &#123;</span><br><span class="line">	// Map unique pod name to outer volume name to MountedVolume.</span><br><span class="line">	mountedVolumesForPod := make(map[volumetypes.UniquePodName]map[string]cache.MountedVolume)</span><br><span class="line">	if utilfeature.DefaultFeatureGate.Enabled(features.ExpandInUsePersistentVolumes) &#123;</span><br><span class="line">		for _, mountedVolume := range dswp.actualStateOfWorld.GetMountedVolumes() &#123;</span><br><span class="line">			mountedVolumes, exist := mountedVolumesForPod[mountedVolume.PodName]</span><br><span class="line">			if !exist &#123;</span><br><span class="line">				mountedVolumes = make(map[string]cache.MountedVolume)</span><br><span class="line">				mountedVolumesForPod[mountedVolume.PodName] = mountedVolumes</span><br><span class="line">			&#125;</span><br><span class="line">			mountedVolumes[mountedVolume.OuterVolumeSpecName] = mountedVolume</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	processedVolumesForFSResize := sets.NewString()</span><br><span class="line">	for _, pod := range dswp.podManager.GetPods() &#123;</span><br><span class="line">		if dswp.podStateProvider.ShouldPodContainersBeTerminating(pod.UID) &#123;</span><br><span class="line">			// Do not (re)add volumes for pods that can&#x27;t also be starting containers</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line">		dswp.processPodVolumes(pod, mountedVolumesForPod, processedVolumesForFSResize)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">func (rc *reconciler) cleanupMounts(volume podVolume) &#123;</span><br><span class="line">	klog.V(2).InfoS(&quot;Reconciler sync states: could not find volume information in desired state, clean up the mount points&quot;, &quot;podName&quot;, volume.podName, &quot;volumeSpecName&quot;, volume.volumeSpecName)</span><br><span class="line">	mountedVolume := operationexecutor.MountedVolume&#123;</span><br><span class="line">		PodName:             volume.podName,</span><br><span class="line">		VolumeName:          v1.UniqueVolumeName(volume.volumeSpecName),</span><br><span class="line">		InnerVolumeSpecName: volume.volumeSpecName,</span><br><span class="line">		PluginName:          volume.pluginName,</span><br><span class="line">		PodUID:              types.UID(volume.podName),</span><br><span class="line">	&#125;</span><br><span class="line">	// TODO: Currently cleanupMounts only includes UnmountVolume operation. In the next PR, we will add</span><br><span class="line">	// to unmount both volume and device in the same routine.</span><br><span class="line">	err := rc.operationExecutor.UnmountVolume(mountedVolume, rc.actualStateOfWorld, rc.kubeletPodsDir)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		klog.ErrorS(err, mountedVolume.GenerateErrorDetailed(&quot;volumeHandler.UnmountVolumeHandler for UnmountVolume failed&quot;, err).Error())</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>But in this time, the container was not finished the container termination, so the volume remove failed, this is the last chance to recycle the volume:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[CSI local driver]2024/03/29 03:10:59 logging.go:26: Serving /csi.v1.Node/NodeUnpublishVolume: req=volume_id:&quot;csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot; target_path:&quot;/var/mnt/kubelet/pods/8c76f1db-b963-4cfc-96b7-6f81fd9781f6/volumes/kubernetes.io~csi/data/mount&quot; </span><br><span class="line">[CSI local driver]2024/03/29 03:10:59 server.go:1111: Looking up volume with id=vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11</span><br><span class="line">[CSI local driver]2024/03/29 03:10:59 lvm.go:830: Executing: /usr/sbin/lvs --reportformat=json --units=b --nosuffix --options=lv_name,lv_size,vg_name,lv_path vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11</span><br><span class="line">                  &#123;&quot;lv_name&quot;:&quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;, &quot;lv_size&quot;:&quot;21474836480&quot;, &quot;vg_name&quot;:&quot;vg10000&quot;, &quot;lv_path&quot;:&quot;/dev/vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;&#125;</span><br><span class="line">[CSI local driver]2024/03/29 03:11:03 server.go:1139: Removing volume with id=vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11</span><br><span class="line">[CSI local driver]2024/03/29 03:11:03 lvm.go:830: Executing: /usr/sbin/lvs --reportformat=json --units=b --nosuffix --options=lv_name,lv_size,vg_name,lv_path vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11</span><br><span class="line">                  &#123;&quot;lv_name&quot;:&quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;, &quot;lv_size&quot;:&quot;21474836480&quot;, &quot;vg_name&quot;:&quot;vg10000&quot;, &quot;lv_path&quot;:&quot;/dev/vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;&#125;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StdoutBuf - &quot;Calling mkfs&quot;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StderrBuf - &quot;mke2fs 1.45.5 (07-Jan-2020)&quot;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StderrBuf - &quot;/dev/vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11 is apparently in use by the system; will not make a filesystem here!&quot;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StdoutBuf - &quot;Calling wipefs&quot;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StderrBuf - &quot;wipefs: error: /dev/vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11: probing initialization failed: Device or resource busy&quot;</span><br><span class="line">2024/03/29 03:11:09 Cleanup lv &quot;vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11&quot;: StdoutBuf - &quot;Quick reset completed&quot;</span><br><span class="line">[CSI local driver]2024/03/29 03:11:09 lvm.go:830: Executing: /usr/sbin/lvremove -f vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11</span><br><span class="line">[CSI local driver]2024/03/29 03:11:18 lvm.go:837: stderr: Logical volume vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11 contains a filesystem in use.</span><br><span class="line">[CSI local driver]2024/03/29 03:11:18 logging.go:30: /csi.v1.Node/NodeUnpublishVolume failed: err=rpc error: code = Internal desc = rpc error: code = Internal desc = Failed to remove volume: Failed to lvremove lv vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11: Logical volume vg10000/vg10000_csi-17ef0134f9c76245a954e751a3ebdb57a965d6cf5ea66a6f19bc4b6aa37bad11 contains a filesystem in use.</span><br></pre></td></tr></table></figure>


<p>So the conditions of producing orphan csi inline volume should be:</p>
<ol>
<li>Pod terminating</li>
<li>Kubelet restart or shutdown during pod terminating</li>
<li>Kubelet reconstructvolume failed and start unmount before container shutdown</li>
</ol>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>The upstream has reported and fixed this issue at 1.25 version: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/108997">https://github.com/kubernetes/kubernetes/pull/108997</a></p>
<p>I backport the related pr into our kubernetes repo:  <a target="_blank" rel="noopener" href="https://github.corp.ebay.com/tess/kubernetes/pull/2289">https://github.corp.ebay.com/tess/kubernetes/pull/2289</a></p>
<p>Before the bug fix rollout, we need manually remove the orphan volume, else it might impact the new pod creating local pvc.</p>
<p>After I audit, I only see the orphan volumes in cluster 40. We can do a change to fix them after kubelet rollout. </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/01/cgroup%20v2%20iocost%20records/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/01/cgroup%20v2%20iocost%20records/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-01 16:56:01" itemprop="dateCreated datePublished" datetime="2024-04-01T16:56:01+08:00">2024-04-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-12 18:18:53" itemprop="dateModified" datetime="2024-05-12T18:18:53+08:00">2024-05-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* per device */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ioc</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rq_qos</span>			<span class="title">rqos</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="type">bool</span>				enabled;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">ioc_params</span>		<span class="title">params</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">ioc_margins</span>		<span class="title">margins</span>;</span></span><br><span class="line">	u32				period_us;</span><br><span class="line">	u32				timer_slack_ns;</span><br><span class="line">	u64				vrate_min;</span><br><span class="line">	u64				vrate_max;</span><br><span class="line"></span><br><span class="line">	<span class="type">spinlock_t</span>			lock;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">timer_list</span>		<span class="title">timer</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>		<span class="title">active_iocgs</span>;</span>	<span class="comment">/* active cgroups */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">ioc_pcpu_stat</span> __<span class="title">percpu</span>	*<span class="title">pcpu_stat</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">enum</span> <span class="title">ioc_running</span>		<span class="title">running</span>;</span></span><br><span class="line">	<span class="type">atomic64_t</span>			vtime_rate;</span><br><span class="line">	u64				vtime_base_rate;</span><br><span class="line">	s64				vtime_err;</span><br><span class="line"></span><br><span class="line">	<span class="type">seqcount_spinlock_t</span>		period_seqcount;</span><br><span class="line">	u64				period_at;	<span class="comment">/* wallclock starttime */</span></span><br><span class="line">	u64				period_at_vtime; <span class="comment">/* vtime starttime */</span></span><br><span class="line"></span><br><span class="line">	<span class="type">atomic64_t</span>			cur_period;	<span class="comment">/* inc&#x27;d each period */</span></span><br><span class="line">	<span class="type">int</span>				busy_level;	<span class="comment">/* saturation history */</span></span><br><span class="line"></span><br><span class="line">	<span class="type">bool</span>				weights_updated;</span><br><span class="line">	<span class="type">atomic_t</span>			hweight_gen;	<span class="comment">/* for lazy hweights */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* debt forgivness */</span></span><br><span class="line">	u64				dfgv_period_at;</span><br><span class="line">	u64				dfgv_period_rem;</span><br><span class="line">	u64				dfgv_usage_us_sum;</span><br><span class="line"></span><br><span class="line">	u64				autop_too_fast_at;</span><br><span class="line">	u64				autop_too_slow_at;</span><br><span class="line">	<span class="type">int</span>				autop_idx;</span><br><span class="line">	<span class="type">bool</span>				user_qos_params:<span class="number">1</span>;</span><br><span class="line">	<span class="type">bool</span>				user_cost_model:<span class="number">1</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* per device-cgroup pair */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ioc_gq</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">blkg_policy_data</span>		<span class="title">pd</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">ioc</span>			*<span class="title">ioc</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * A iocg can get its weight from two sources - an explicit</span></span><br><span class="line"><span class="comment">	 * per-device-cgroup configuration or the default weight of the</span></span><br><span class="line"><span class="comment">	 * cgroup.  `cfg_weight` is the explicit per-device-cgroup</span></span><br><span class="line"><span class="comment">	 * configuration.  `weight` is the effective considering both</span></span><br><span class="line"><span class="comment">	 * sources.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * When an idle cgroup becomes active its `active` goes from 0 to</span></span><br><span class="line"><span class="comment">	 * `weight`.  `inuse` is the surplus adjusted active weight.</span></span><br><span class="line"><span class="comment">	 * `active` and `inuse` are used to calculate `hweight_active` and</span></span><br><span class="line"><span class="comment">	 * `hweight_inuse`.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * `last_inuse` remembers `inuse` while an iocg is idle to persist</span></span><br><span class="line"><span class="comment">	 * surplus adjustments.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * `inuse` may be adjusted dynamically during period. `saved_*` are used</span></span><br><span class="line"><span class="comment">	 * to determine and track adjustments.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">  </span><br><span class="line">	u32				cfg_weight;</span><br><span class="line">	u32				weight;</span><br><span class="line">	u32				active;</span><br><span class="line">	u32				inuse;</span><br><span class="line"></span><br><span class="line">	u32				last_inuse;</span><br><span class="line">	s64				saved_margin;</span><br><span class="line"></span><br><span class="line">	<span class="type">sector_t</span>			cursor;		<span class="comment">/* to detect randio */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * `vtime` is this iocg&#x27;s vtime cursor which progresses as IOs are</span></span><br><span class="line"><span class="comment">	 * issued.  If lagging behind device vtime, the delta represents</span></span><br><span class="line"><span class="comment">	 * the currently available IO budget.  If running ahead, the</span></span><br><span class="line"><span class="comment">	 * overage.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * `vtime_done` is the same but progressed on completion rather</span></span><br><span class="line"><span class="comment">	 * than issue.  The delta behind `vtime` represents the cost of</span></span><br><span class="line"><span class="comment">	 * currently in-flight IOs.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">atomic64_t</span>			vtime;</span><br><span class="line">	<span class="type">atomic64_t</span>			done_vtime;</span><br><span class="line">	u64				abs_vdebt;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* current delay in effect and when it started */</span></span><br><span class="line">	u64				delay;</span><br><span class="line">	u64				delay_at;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * The period this iocg was last active in.  Used for deactivation</span></span><br><span class="line"><span class="comment">	 * and invalidating `vtime`.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">atomic64_t</span>			active_period;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>		<span class="title">active_list</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* see __propagate_weights() and current_hweight() for details */</span></span><br><span class="line">	u64				child_active_sum;</span><br><span class="line">	u64				child_inuse_sum;</span><br><span class="line">	u64				child_adjusted_sum;</span><br><span class="line">	<span class="type">int</span>				hweight_gen;</span><br><span class="line">	u32				hweight_active;</span><br><span class="line">	u32				hweight_inuse;</span><br><span class="line">	u32				hweight_donating;</span><br><span class="line">	u32				hweight_after_donation;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>		<span class="title">walk_list</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>		<span class="title">surplus_list</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">wait_queue_head</span>		<span class="title">waitq</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">hrtimer</span>			<span class="title">waitq_timer</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* timestamp at the latest activation */</span></span><br><span class="line">	u64				activated_at;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* statistics */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">iocg_pcpu_stat</span> __<span class="title">percpu</span>	*<span class="title">pcpu_stat</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">iocg_stat</span>		<span class="title">stat</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">iocg_stat</span>		<span class="title">last_stat</span>;</span></span><br><span class="line">	u64				last_stat_abs_vusage;</span><br><span class="line">	u64				usage_delta_us;</span><br><span class="line">	u64				wait_since;</span><br><span class="line">	u64				indebt_since;</span><br><span class="line">	u64				indelay_since;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* this iocg&#x27;s depth in the hierarchy and ancestors including self */</span></span><br><span class="line">	<span class="type">int</span>				level;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">ioc_gq</span>			*<span class="title">ancestors</span>[];</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<p>Y_4K&#x2F;y_b &#x3D; a + b* X_4K &#x2F; X_b</p>
<p>Y_4k &#x3D; a* X_4k <em>Y_b &#x2F; X_b.   a&#x3D; Y_4k * X_b &#x2F; (X_4k</em>y_b)</p>
<p>Ssd iops: a_8k&#x3D; 70k<em>8k &#x2F; (4k</em>51k)  &#x3D; 2.745</p>
<p>a_16k &#x3D; 70k * 16k &#x2F; ( 29k * 4k) &#x3D; </p>
<p>y &#x3D; a+ bx + cx2</p>
<p>IOPS &#x3D; y&#x2F;x &#x3D; 70M&#x2F;x + 60 - 2 * x</p>
<p>BPS &#x3D; 70M + 60x - 2x^2</p>
<p>270M &#x3D; a + b * 4k + c * 16M</p>
<p>400M &#x3D; a + b * 8k + c * 64M</p>
<p>460M &#x3D; a + b * 16k + c * 256M</p>
<p>130M &#x3D; 4k  * b+ c * 48M</p>
<p>60M &#x3D; 8k * b + c * 192M</p>
<p>200M &#x3D; - c * 96M</p>
<p>c&#x3D; -2.08</p>
<p>b &#x3D; 57.42k</p>
<p>a &#x3D; 460M - 918.72M + 532.48M &#x3D; 74M</p>
<p>(y_4k, 4k). </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2023-12-15-what-is-wa-and-how-is-it-calculated/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2023-12-15-what-is-wa-and-how-is-it-calculated/" class="post-title-link" itemprop="url">what is wa and how is it calculated</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 13:00:55" itemprop="dateCreated datePublished" datetime="2024-03-10T13:00:55+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/system/" itemprop="url" rel="index"><span itemprop="name">system</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Question-wa-usage"><a href="#Question-wa-usage" class="headerlink" title="Question: wa usage"></a>Question: wa usage</h3><p>When you run top, you can see the usage of wa. What does it means and how it calculated?</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  0.1 us,  2.4 sy,  0.0 ni, 93.6 <span class="built_in">id</span>,  3.9 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br></pre></td></tr></table></figure>

<p>Values related to processor utilization are displayed on the third line. They provide insight into exactly what the CPUs are doing.</p>
<ul>
<li><code>us</code> is the percent of time spent running user processes.</li>
<li><code>sy</code> is the percent of time spent running the kernel.</li>
<li><code>ni</code> is the percent of time spent running processes with manually configured <a target="_blank" rel="noopener" href="https://www.redhat.com/sysadmin/manipulate-process-priority">nice values</a>.</li>
<li><code>id</code> is the percent of time idle (if high, CPU may be overworked).</li>
<li><strong><code>wa</code> is the percent of wait time (if high, CPU is waiting for I&#x2F;O access).</strong></li>
<li><code>hi</code> is the percent of time managing hardware interrupts.</li>
<li><code>si</code> is the percent of time managing software interrupts.</li>
<li><code>st</code> is the percent of virtual CPU time waiting for access to physical CPU.</li>
</ul>
<p>In the context of the <code>top</code> command in Unix-like operating systems, the “wa” field represents the percentage of time the CPU spends waiting for I&#x2F;O operations to complete. Specifically, it stands for “waiting for I&#x2F;O.”</p>
<p>The calculation includes the time the CPU is idle while waiting for data to be read from or written to storage devices such as hard drives or SSDs. High values in the “wa” field may indicate that the system is spending a significant amount of time waiting for I&#x2F;O operations to complete, which could be a bottleneck if not addressed.</p>
<p>The formula for calculating the “wa” value is as follows:</p>
<p><strong><code>wa %=(Time spent waiting for I/O / Total CPU time)×100</code></strong></p>
<p>Also we can use <code>vmstat 1</code> to watch the <code>wa</code> state in system, but it is the not the percent:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vmstat 1</span></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 5  9      0 25994684     24 64404172    0    0     1    16    0    0  4  3 93  0  0</span><br><span class="line"> 0 10      0 25994436     24 64404172    0    0 342776 341104 63906 52162  2 10 83  4  3</span><br><span class="line"> 0 10      0 25994188     24 64404172    0    0 350392 350968 65593 52742  2 12 80  3  3</span><br><span class="line"> 1  9      0 25994188     24 64404172    0    0 342656 341128 63793 51367  2 11 80  3  4</span><br><span class="line"> 0 10      0 25994188     24 64404172    0    0 350760 350216 65439 52811  2 10 81  3  4</span><br><span class="line"> 5  8      0 25993940     24 64404172    0    0 355224 358952 66762 52421  2 10 80  3  5</span><br><span class="line"> 0 10      0 25993444     24 64404172    0    0 350536 350576 64998 52346  1 10 81  3  4</span><br><span class="line"> 1 10      0 25992948     24 64404172    0    0 348344 347912 64709 51990  1 11 81  3  4</span><br><span class="line"> 2 10      0 25992700     24 64404172    0    0 351944 349616 65443 51371  2 11 80  3  5</span><br><span class="line"> 0 10      0 26000764     24 64404172    0    0 343368 345000 64589 51969  2 12 80  3  4</span><br><span class="line"> 1  9      0 26000516     24 64404172    0    0 348976 352352 65800 53079  1  9 84  3  3</span><br><span class="line"> 1  9      0 26000516     24 64404172    0    0 345520 341800 63737 51454  1  8 84  3  3</span><br><span class="line"> 1  9      0 26000516     24 64404172    0    0 349192 352336 65719 52241  2  9 82  3  4</span><br><span class="line"> 1  9      0 26000516     24 64404172    0    0 352384 355696 66567 52232  2 11 80  3  4</span><br><span class="line"> 8  5      0 26000268     24 64404172    0    0 346368 345496 64541 52114  2 12 80  3  3</span><br><span class="line"> 0 10      0 26000020     24 64404172    0    0 340064 341296 63603 51670  2 11 81  3  2</span><br><span class="line"> 0  0      0 26007496     24 64399156    0    0 306736 306040 57770 46495  2 10 82  3  3</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     0  853 1480  0  0 100  0  0</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     0  871 1553  0  0 100  0  0</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     0  748 1430  0  0 100  0  0</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     2  731 1399  0  0 100  0  0</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     0  695 1319  0  0 100  0  0</span><br><span class="line"> 0  0      0 26007588     24 64398828    0    0     0     0  743 1418  0  0 100  0  0</span><br></pre></td></tr></table></figure>

 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Procs</span><br><span class="line">    r: The number of processes waiting for run time.</span><br><span class="line">    b: The number of processes in uninterruptible sleep.</span><br><span class="line">Memory</span><br><span class="line">    swpd: the amount of virtual memory used.</span><br><span class="line">    free: the amount of idle memory.</span><br><span class="line">    buff: the amount of memory used as buffers.</span><br><span class="line">    cache: the amount of memory used as cache.</span><br><span class="line">    inact: the amount of inactive memory. (-a option)</span><br><span class="line">    active: the amount of active memory. (-a option)</span><br><span class="line">Swap</span><br><span class="line">    si: Amount of memory swapped in from disk (/s).</span><br><span class="line">    so: Amount of memory swapped to disk (/s).</span><br><span class="line">IO</span><br><span class="line">    bi: Blocks received from a block device (blocks/s).</span><br><span class="line">    bo: Blocks sent to a block device (blocks/s).</span><br><span class="line">System</span><br><span class="line">    in: The number of interrupts per second, including the clock.</span><br><span class="line">    cs: The number of context switches per second.</span><br><span class="line">CPU</span><br><span class="line">    These are percentages of total CPU time.</span><br><span class="line">    us: Time spent running non-kernel code. (user time, including nice time)</span><br><span class="line">    sy: Time spent running kernel code. (system time)</span><br><span class="line">    id: Time spent idle. Prior to Linux 2.5.41, this includes IO-wait time.</span><br><span class="line">    wa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.</span><br><span class="line">    st: Time stolen from a virtual machine. Prior to Linux 2.6.11, unknown.</span><br></pre></td></tr></table></figure>

<p>In summary, a high “wa” value in the output of <code>top</code> suggests that your system is spending a considerable amount of time waiting for I&#x2F;O operations to be completed, which could impact overall system performance. Investigating and optimizing disk I&#x2F;O can be beneficial in such cases, possibly by improving disk performance, optimizing file systems, or identifying and addressing specific I&#x2F;O-intensive processes. We can use <code>iotop</code> to find the high io or slow io processes in system:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Current DISK READ:     341.78 M/s | Current DISK WRITE:     340.53 M/s</span><br><span class="line">    TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND</span><br><span class="line">3487445 be/4 root       34.44 M/s   33.36 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487446 be/4 root       33.40 M/s   34.27 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487447 be/4 root       34.10 M/s   33.78 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487448 be/4 root       32.21 M/s   31.64 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487449 be/4 root       34.22 M/s   34.44 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487450 be/4 root       34.46 M/s   34.33 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487451 be/4 root       34.17 M/s   34.21 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487452 be/4 root       33.05 M/s   32.95 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487453 be/4 root       34.23 M/s   34.74 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">3487454 be/4 root       37.51 M/s   36.79 M/s  ?unavailable?  fio -filename=/mnt/hostroot/var/mnt/testfile -direct=1 -iodepth 64 -thread -rw=randrw -ioengine=libaio -bs=8k -size=20G -numjobs=10 -group_reporting --runtime=100 -name=mytest</span><br><span class="line">      1 be/4 root        0.00 B/s    0.00 B/s  ?unavailable?  systemd --switched-root --system --deserialize 29</span><br><span class="line">      2 be/4 root        0.00 B/s    0.00 B/s  ?unavailable?  [kthreadd]</span><br><span class="line">      3 be/4 root        0.00 B/s    0.00 B/s  ?unavailable?  [rcu_gp]</span><br><span class="line">      4 be/4 root        0.00 B/s    0.00 B/s  ?unavailable?  [rcu_par_gp]</span><br><span class="line">      6 be/4 root        0.00 B/s    0.00 B/s  ?unavailable?  [kworker/0:0H-events_highpri]</span><br></pre></td></tr></table></figure>

<h3 id="Code-tracing"><a href="#Code-tracing" class="headerlink" title="Code tracing"></a>Code tracing</h3><p>From strace the top command, the <code>wa</code>  value is get the status from <code>/proc/*/stat</code>. The <code>/proc/*/stat </code>is wrote by the proc ops and get the iowait time from <code>kernel_cpustat.cpustat[CPUTIME_IOWAIT]</code> accroding to the code <code>fs/proc/stat.c</code>. </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">proc_ops</span> <span class="title">stat_proc_ops</span> =</span> &#123;</span><br><span class="line">	.proc_flags	= PROC_ENTRY_PERMANENT,</span><br><span class="line">	.proc_open	= stat_open,</span><br><span class="line">	.proc_read_iter	= seq_read_iter,</span><br><span class="line">	.proc_lseek	= seq_lseek,</span><br><span class="line">	.proc_release	= single_release,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> __init <span class="title function_">proc_stat_init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	proc_create(<span class="string">&quot;stat&quot;</span>, <span class="number">0</span>, <span class="literal">NULL</span>, &amp;stat_proc_ops);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">stat_open</span><span class="params">(<span class="keyword">struct</span> inode *inode, <span class="keyword">struct</span> file *file)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> size = <span class="number">1024</span> + <span class="number">128</span> * num_online_cpus();</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* minimum size to display an interrupt count : 2 bytes */</span></span><br><span class="line">	size += <span class="number">2</span> * nr_irqs;</span><br><span class="line">	<span class="keyword">return</span> single_open_size(file, show_stat, <span class="literal">NULL</span>, size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">show_stat</span><span class="params">(<span class="keyword">struct</span> seq_file *p, <span class="type">void</span> *v)</span></span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  		iowait		+= get_iowait_time(&amp;kcpustat, i);</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> u64 <span class="title function_">get_iowait_time</span><span class="params">(<span class="keyword">struct</span> kernel_cpustat *kcs, <span class="type">int</span> cpu)</span></span><br><span class="line">&#123;</span><br><span class="line">	u64 iowait, iowait_usecs = <span class="number">-1ULL</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (cpu_online(cpu))</span><br><span class="line">		iowait_usecs = get_cpu_iowait_time_us(cpu, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (iowait_usecs == <span class="number">-1ULL</span>)</span><br><span class="line">		<span class="comment">/* !NO_HZ or cpu offline so we can rely on cpustat.iowait */</span></span><br><span class="line">		iowait = kcs-&gt;cpustat[CPUTIME_IOWAIT];</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		iowait = iowait_usecs * NSEC_PER_USEC;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> iowait;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>In the Linux kernel, the calculation of the “wa” (waiting for I&#x2F;O) value that is reported by tools like <code>top</code> is handled within the kernel’s scheduler. The specific code responsible for updating the CPU usage statistics can be found in the <code>kernel/sched/cputime.c</code> file.</p>
<p>One of the key functions related to this is <code>account_idle_time()</code>. </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Account for idle time.</span></span><br><span class="line"><span class="comment"> * @cputime: the CPU time spent in idle wait</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">account_idle_time</span><span class="params">(u64 cputime)</span></span><br><span class="line">&#123;</span><br><span class="line">	u64 *cpustat = kcpustat_this_cpu-&gt;cpustat;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rq</span> *<span class="title">rq</span> =</span> this_rq();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (<span class="type">atomic_read</span>(&amp;rq-&gt;nr_iowait) &gt; <span class="number">0</span>)</span><br><span class="line">		cpustat[CPUTIME_IOWAIT] += cputime;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		cpustat[CPUTIME_IDLE] += cputime;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	u32 nr_iowait;		<span class="comment">/* number of blocked threads (waiting for I/O)    */</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>This function is part of the kernel’s scheduler and is responsible for updating the various CPU time statistics, including the time spent waiting for I&#x2F;O. The function takes into account different CPU states, such as idle time and time spent waiting for I&#x2F;O.When The blocked threads with waiting for I&#x2F;O, the cpu time accumulated into CPUTIME_IOWAIT.</p>
<p>Here is a basic outline of how the “wa” time is accounted for in the Linux kernel:</p>
<ol>
<li><strong>Idle time accounting:</strong> The kernel keeps track of the time the CPU spends in an idle state, waiting for tasks to execute.</li>
<li><strong>I&#x2F;O wait time accounting:</strong> When a process is waiting for I&#x2F;O operations (such as reading or writing to a disk), the kernel accounts for this time in the appropriate CPU state, including the “wa” time.</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># block/fops.c</span></span><br><span class="line"><span class="type">static</span> <span class="type">ssize_t</span> __blkdev_direct_IO(<span class="keyword">struct</span> kiocb *iocb, <span class="keyword">struct</span> iov_iter *iter,</span><br><span class="line">		<span class="type">unsigned</span> <span class="type">int</span> nr_pages)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  	<span class="keyword">for</span> (;;) &#123;</span><br><span class="line">		set_current_state(TASK_UNINTERRUPTIBLE);</span><br><span class="line">		<span class="keyword">if</span> (!READ_ONCE(dio-&gt;waiter))</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		blk_io_schedule();</span><br><span class="line">	&#125;</span><br><span class="line">	__set_current_state(TASK_RUNNING);</span><br><span class="line">  ...</span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># block/blk-core.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">blk_io_schedule</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">/* Prevent hang_check timer from firing at us during very long I/O */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> timeout = sysctl_hung_task_timeout_secs * HZ / <span class="number">2</span>;</span><br><span class="line">	<span class="keyword">if</span> (timeout)</span><br><span class="line">		io_schedule_timeout(timeout);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		io_schedule();</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(blk_io_schedule);</span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># kernel/sched/core.c</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This task is about to go to sleep on IO. Increment rq-&gt;nr_iowait so</span></span><br><span class="line"><span class="comment"> * that process accounting knows that this is a task in IO wait state.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">long</span> __sched <span class="title function_">io_schedule_timeout</span><span class="params">(<span class="type">long</span> timeout)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> token;</span><br><span class="line">	<span class="type">long</span> ret;</span><br><span class="line"></span><br><span class="line">	token = io_schedule_prepare();</span><br><span class="line">	ret = schedule_timeout(timeout);</span><br><span class="line">	io_schedule_finish(token);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(io_schedule_timeout);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">io_schedule_prepare</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> old_iowait = current-&gt;in_iowait;</span><br><span class="line"></span><br><span class="line">	current-&gt;in_iowait = <span class="number">1</span>;</span><br><span class="line">	blk_flush_plug(current-&gt;plug, <span class="literal">true</span>);</span><br><span class="line">	<span class="keyword">return</span> old_iowait;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">io_schedule_finish</span><span class="params">(<span class="type">int</span> token)</span></span><br><span class="line">&#123;</span><br><span class="line">	current-&gt;in_iowait = token;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">asmlinkage __visible <span class="type">void</span> __sched <span class="title function_">schedule</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">tsk</span> =</span> current;</span><br><span class="line"></span><br><span class="line">	sched_submit_work(tsk);</span><br><span class="line">	<span class="keyword">do</span> &#123;</span><br><span class="line">		preempt_disable();</span><br><span class="line">		__schedule(SM_NONE);</span><br><span class="line">		sched_preempt_enable_no_resched();</span><br><span class="line">	&#125; <span class="keyword">while</span> (need_resched());</span><br><span class="line">	sched_update_worker(tsk);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(schedule);</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> __sched notrace __schedule(<span class="type">unsigned</span> <span class="type">int</span> sched_mode)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">			<span class="keyword">if</span> (prev-&gt;in_iowait) &#123;</span><br><span class="line">				<span class="type">atomic_inc</span>(&amp;rq-&gt;nr_iowait);</span><br><span class="line">				delayacct_blkio_start();</span><br><span class="line">			&#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># kernel/time/timer.c</span></span><br><span class="line"><span class="type">signed</span> <span class="type">long</span> __sched <span class="title function_">schedule_timeout</span><span class="params">(<span class="type">signed</span> <span class="type">long</span> timeout)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">process_timer</span> <span class="title">timer</span>;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> expire;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">switch</span> (timeout)</span><br><span class="line">	&#123;</span><br><span class="line">	<span class="keyword">case</span> MAX_SCHEDULE_TIMEOUT:</span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * These two special cases are useful to be comfortable</span></span><br><span class="line"><span class="comment">		 * in the caller. Nothing more. We could take</span></span><br><span class="line"><span class="comment">		 * MAX_SCHEDULE_TIMEOUT from one of the negative value</span></span><br><span class="line"><span class="comment">		 * but I&#x27; d like to return a valid offset (&gt;=0) to allow</span></span><br><span class="line"><span class="comment">		 * the caller to do everything it want with the retval.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		schedule();</span><br><span class="line">		<span class="keyword">goto</span> out;</span><br><span class="line">      ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span></span><br><span class="line"><span class="title function_">try_to_wake_up</span><span class="params">(<span class="keyword">struct</span> task_struct *p, <span class="type">unsigned</span> <span class="type">int</span> state, <span class="type">int</span> wake_flags)</span></span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">   <span class="keyword">if</span> (task_cpu(p) != cpu) &#123;</span><br><span class="line">		<span class="keyword">if</span> (p-&gt;in_iowait) &#123;</span><br><span class="line">			delayacct_blkio_end(p);</span><br><span class="line">			<span class="type">atomic_dec</span>(&amp;task_rq(p)-&gt;nr_iowait);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		wake_flags |= WF_MIGRATED;</span><br><span class="line">		psi_ttwu_dequeue(p);</span><br><span class="line">		set_task_cpu(p, cpu);</span><br><span class="line">	&#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2023-12-15-blktrace-block-io-lifecycle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2023-12-15-blktrace-block-io-lifecycle/" class="post-title-link" itemprop="url">blktrace block io lifecycle</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:54:25" itemprop="dateCreated datePublished" datetime="2024-03-10T12:54:25+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/system/" itemprop="url" rel="index"><span itemprop="name">system</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Question-trace-the-life-of-IO-by-blktrace-blkparse"><a href="#Question-trace-the-life-of-IO-by-blktrace-blkparse" class="headerlink" title="Question: trace the life of IO by blktrace&#x2F;blkparse"></a>Question: trace the life of IO by blktrace&#x2F;blkparse</h3><p><a target="_blank" rel="noopener" href="https://linux.die.net/man/8/blktrace">blktrace</a></p>
<p><a target="_blank" rel="noopener" href="https://linux.die.net/man/1/blkparse">blkparse</a></p>
<p>Investigate the blktrace implementation to understand the trace hook of the blk IO stack?</p>
<h3 id="blktrace-to-parse-the-block-io"><a href="#blktrace-to-parse-the-block-io" class="headerlink" title="blktrace to parse the block io"></a>blktrace to parse the block io</h3><p><code>blktrace</code> explores the Linux kernel tracepoint infrastructure to track requests in-flight through the block I&#x2F;O stack. It traces everything that goes through to block devices, while observing timing information. </p>
<p>First we using <code>dd</code> command to make a write IO (the read IO is the same). </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// write to a file with direct io by dd command</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=testfile bs=16k count=1024000 oflag=direct</span></span><br><span class="line">1024000+0 records in</span><br><span class="line">1024000+0 records out</span><br><span class="line">16777216000 bytes (17 GB, 16 GiB) copied, 111.433 s, 151 MB/s</span><br></pre></td></tr></table></figure>

<p>Using<code>blktrace</code> and <code>blkparse</code> analize results:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">blktrace -d /dev/vda -o res</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">blkparse -i res</span></span><br><span class="line">device  </span><br><span class="line">252,0   10        3     0.000238760       0  C  WS 49724200 + 32 [0]</span><br><span class="line">252,0    0       17     0.000261770 3418552  A  WS 48720712 + 32 &lt;- (253,0) 48718664</span><br><span class="line">252,0    0       18     0.000262000 3418552  A  WS 49724232 + 32 &lt;- (252,3) 48720712</span><br><span class="line">252,0    0       19     0.000262192 3418552  Q  WS 49724232 + 32 [dd]</span><br><span class="line">252,0    0       20     0.000263132 3418552  G  WS 49724232 + 32 [dd]</span><br><span class="line">252,0    0       21     0.000263335 3418552  P   N [dd]</span><br><span class="line">252,0    0       22     0.000263494 3418552  U   N [dd] 1</span><br><span class="line">252,0    0       23     0.000263719 3418552  I  WS 49724232 + 32 [dd]</span><br><span class="line">252,0    0       24     0.000264296 3418552  D  WS 49724232 + 32 [dd]</span><br><span class="line">252,0   10        4     0.000341566       0  C  WS 49724232 + 32 [0]</span><br><span class="line">252,0    0       25     0.000366914 3418552  A  WS 48720744 + 32 &lt;- (253,0) 48718696</span><br><span class="line">252,0    0       26     0.000367235 3418552  A  WS 49724264 + 32 &lt;- (252,3) 48720744</span><br><span class="line">252,0    0       27     0.000367410 3418552  Q  WS 49724264 + 32 [dd]</span><br><span class="line">252,0    0       28     0.000368423 3418552  G  WS 49724264 + 32 [dd]</span><br><span class="line">252,0    0       29     0.000368612 3418552  P   N [dd]</span><br><span class="line">252,0    0       30     0.000368797 3418552  U   N [dd] 1</span><br><span class="line">252,0    0       31     0.000369036 3418552  I  WS 49724264 + 32 [dd]</span><br><span class="line">252,0    0       32     0.000369730 3418552  D  WS 49724264 + 32 [dd]</span><br><span class="line">252,0   10        5     0.000453876       0  C  WS 49724264 + 32 [0]</span><br><span class="line">...</span><br><span class="line">252,0   10    91033     2.279081418 3405085  C  WS 50399976 + 32 [0]</span><br><span class="line">252,0   10   232460     5.618988454 3405085  C  WS 51349952 + 32 [0]</span><br><span class="line">252,0   10   318363     8.424729857 3405085  C  WM 39888904 + 16 [0]</span><br><span class="line">252,0   10   318364     8.424732534 3405085  C  WM 267886593 + 1 [0]</span><br><span class="line">252,0   10   318365     8.424734981 3405085  C  WM 267886600 + 16 [0]</span><br><span class="line">252,0   10   318366     8.424737948 3405085  C  WM 267925376 + 32 [0]</span><br><span class="line">252,0   10   318367     8.424750755 3405085  C  WM 267924512 + 32 [0]</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">Total (res):</span><br><span class="line"> Reads Queued:           0,        0KiB  Writes Queued:       70567,     1128MiB</span><br><span class="line"> Read Dispatches:        3,        0KiB  Write Dispatches:    70559,     1128MiB</span><br><span class="line"> Reads Requeued:         0               Writes Requeued:         0</span><br><span class="line"> Reads Completed:        3,        0KiB  Writes Completed:    70563,     1128MiB</span><br><span class="line"> Read Merges:            0,        0KiB  Write Merges:            6,       24KiB</span><br><span class="line"> IO unplugs:         70545               Timer unplugs:           0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tracing 267886608</span></span><br><span class="line">252,0    6       71     8.424115456   585  A  WM 267886608 + 8 &lt;- (252,3) 266883088</span><br><span class="line">252,0    6       72     8.424115630   585  Q  WM 267886608 + 8 [xfsaild/dm-0]</span><br><span class="line">252,0    6       73     8.424115962   585  M  WM 267886608 + 8 [xfsaild/dm-0]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tracing 4555007</span></span><br><span class="line">252,0    9        2     8.423915195 3374227  A WFSM 4555007 + 31 &lt;- (252,3) 3551487</span><br><span class="line">252,0    9        3     8.423915869 3374227  Q WFSM 4555007 + 31 [kworker/9:4]</span><br><span class="line">252,0    9        4     8.423918485 3374227  G WFSM 4555007 + 31 [kworker/9:4]</span><br><span class="line">252,0    9        5     8.423927401   240  D WSM 4555007 + 31 [kworker/9:1H]</span><br><span class="line">252,0   10   318350     8.424051685     0  C WSM 4555007 + 31 [0]</span><br><span class="line">252,0   10   318353     8.424169747     0  C WSM 4555007 [0]</span><br></pre></td></tr></table></figure>

<p>![*Screenshot 2023-12-25 at 13.37.09*](&#x2F;Users&#x2F;tashen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;Screenshot 2023-12-25 at 13.37.09.png)</p>
<h4 id="ACTION-IDENTIFIERS"><a href="#ACTION-IDENTIFIERS" class="headerlink" title="ACTION IDENTIFIERS"></a>ACTION IDENTIFIERS</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">The following table shows the various actions which may be</span><br><span class="line">       output:</span><br><span class="line"></span><br><span class="line">       A      IO was remapped to a different device</span><br><span class="line"></span><br><span class="line">       B      IO bounced</span><br><span class="line"></span><br><span class="line">       C      IO completion</span><br><span class="line"></span><br><span class="line">       D      IO issued to driver</span><br><span class="line"></span><br><span class="line">       F      IO front merged with request on queue</span><br><span class="line"></span><br><span class="line">       G      Get request</span><br><span class="line"></span><br><span class="line">       I      IO inserted onto request queue</span><br><span class="line"></span><br><span class="line">       M      IO back merged with request on queue</span><br><span class="line"></span><br><span class="line">       P      Plug request</span><br><span class="line"></span><br><span class="line">       Q      IO handled by request queue code</span><br><span class="line"></span><br><span class="line">       S      Sleep request</span><br><span class="line"></span><br><span class="line">       T      Unplug due to timeout</span><br><span class="line"></span><br><span class="line">       U      Unplug request</span><br><span class="line"></span><br><span class="line">       X      Split</span><br></pre></td></tr></table></figure>

<p>The result is long and there only paste few of them. I try to trace an different sectors and behaviors of block layer.</p>
<p><code>blkparse</code> command still hard to know the total metrics and statistics, so we can use <code>btt</code> to see the statistic of whole table and picture, this is the part of results:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">blkparse -q -i res   -d sda.blk.bin</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">btt -i sda.blk.bin</span></span><br><span class="line"></span><br><span class="line">==================== All Devices ====================</span><br><span class="line"></span><br><span class="line">            ALL           MIN           AVG           MAX           N</span><br><span class="line">--------------- ------------- ------------- ------------- -----------</span><br><span class="line"></span><br><span class="line">Q2Q               0.000001441   0.000119382   0.802839654       70564</span><br><span class="line">Q2G               0.000000497   0.000000797   0.000025123       70559</span><br><span class="line">G2I               0.000000406   0.000000654   0.000128249       70558</span><br><span class="line">Q2M               0.000000133   0.000000271   0.000000631           6</span><br><span class="line">I2D               0.000000411   0.000000663   0.000017267       70558</span><br><span class="line">M2D               0.000031518   0.000071988   0.000116699           6</span><br><span class="line">D2C               0.000064651   0.000079818   0.002640604       70565</span><br><span class="line">Q2C               0.000066315   0.000081939   0.002643331       70565</span><br><span class="line"></span><br><span class="line">==================== Device Overhead ====================</span><br><span class="line"></span><br><span class="line">       DEV |       Q2G       G2I       Q2M       I2D       D2C</span><br><span class="line">---------- | --------- --------- --------- --------- ---------</span><br><span class="line"> (252,  0) |   0.9723%   0.7983%   0.0000%   0.8096%  97.4121%</span><br><span class="line">---------- | --------- --------- --------- --------- ---------</span><br><span class="line">   Overall |   0.9723%   0.7983%   0.0000%   0.8096%  97.4121%</span><br><span class="line"></span><br><span class="line">==================== Device Merge Information ====================</span><br><span class="line"></span><br><span class="line">       DEV |       #Q       #D   Ratio |   BLKmin   BLKavg   BLKmax    Total</span><br><span class="line">---------- | -------- -------- ------- | -------- -------- -------- --------</span><br><span class="line"> (252,  0) |    70565    70559     1.0 |        1       31       32  2257605</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Q-------&gt;G------------&gt;I---------&gt;M-------------------&gt;D-----------------------------&gt;C</span><br><span class="line">|-Q time-|-Insert time-|</span><br><span class="line">|--------- merge time ------------|-merge with other IO|</span><br><span class="line">|----------------scheduler time time-------------------|---driver,adapter,storagetime--|</span><br><span class="line"></span><br><span class="line">|----------------------- await time in iostat output ----------------------------------|</span><br></pre></td></tr></table></figure>

<p>Q2Q — time between requests sent to the block layer </p>
<p>Q2G — time from a block I&#x2F;O is queued to the time it gets a request allocated for it</p>
<p>G2I — time from a request is allocated to the time it is inserted into the device’s queue </p>
<p>Q2M — time from a block I&#x2F;O is queued to the time it gets merged with an existing request </p>
<p>I2D — time from a request is inserted into the device’s queue to the time it is actually issued to the device (time the I&#x2F;O is “idle” on the request queue)</p>
<p>M2D — time from  a block I&#x2F;O is merged with an exiting request until the request is issued to the device </p>
<p>D2C — service time of the request by the device (time the I&#x2F;O is “active” in the driver and on the device)</p>
<p>Q2C — total time spent in the block layer  for a request</p>
<p>Actually the blktrace’s implement is using various linux kernel tracepoint to trace different phase of IO. Here are some of the key tracepoints used by <code>blktrace</code>:</p>
<ol>
<li><code>block_rq_insert</code>: This tracepoint is hit when a request is inserted into the request queue.(Q)</li>
<li><code>block_rq_issue</code>: This tracepoint is hit when a request is issued to the device.(I)</li>
<li><code>block_rq_complete</code>: This tracepoint is hit when a request is completed.(C)</li>
<li><code>block_bio_queue</code>: This tracepoint is hit when a bio is queued.(Q)</li>
<li><code>block_bio_backmerge</code>: This tracepoint is hit when a bio is being merged with the last bio in the request.</li>
<li><code>block_bio_frontmerge</code>: This tracepoint is hit when a bio is being merged with the first bio in the request.</li>
<li><code>block_bio_bounce</code>: This tracepoint is hit when a bio is bounced.</li>
<li><code>block_getrq</code>: This tracepoint is hit when get_request() is called to allocate a request.</li>
<li><code>block_sleeprq</code>: This tracepoint is hit when a process is going to sleep waiting for a request to be available.</li>
<li><code>block_plug</code>: This tracepoint is hit when a plug is inserted into the request queue.</li>
<li><code>block_unplug</code>: This tracepoint is hit when a plug is removed from the request queue.</li>
</ol>
<h3 id="Main-data-structure-in-block-layer"><a href="#Main-data-structure-in-block-layer" class="headerlink" title="Main data structure in block layer"></a>Main data structure in block layer</h3><p>To deepdiv the block layer, i read the code and finding as followes:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * main unit of I/O for the block layer and lower layers (ie drivers and</span></span><br><span class="line"><span class="comment"> * stacking drivers)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bio</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">bio</span>		*<span class="title">bi_next</span>;</span>	<span class="comment">/* request queue link */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">block_device</span>	*<span class="title">bi_bdev</span>;</span></span><br><span class="line">  <span class="type">unsigned</span> <span class="type">long</span>       bi_rw; <span class="comment">/* read or write */</span></span><br><span class="line">  ...</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">bio_vec</span>		*<span class="title">bi_io_vec</span>;</span>	<span class="comment">/* the actual vec list */</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">bvec_iter</span>	<span class="title">bi_iter</span>;</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * struct bio_vec - a contiguous range of physical memory addresses</span></span><br><span class="line"><span class="comment"> * @bv_page:   First page associated with the address range.</span></span><br><span class="line"><span class="comment"> * @bv_len:    Number of bytes in the address range.</span></span><br><span class="line"><span class="comment"> * @bv_offset: Start of the address range relative to the start of @bv_page.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The following holds for a bvec if n * PAGE_SIZE &lt; bv_offset + bv_len:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *   nth_page(@bv_page, n) == @bv_page + n</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This holds because page_is_mergeable() checks the above property.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bio_vec</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span>	*<span class="title">bv_page</span>;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>	bv_len;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>	bv_offset;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bvec_iter</span> &#123;</span></span><br><span class="line">	<span class="type">sector_t</span>		bi_sector;	<span class="comment">/* device address in 512 byte</span></span><br><span class="line"><span class="comment">						   sectors */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		bi_size;	<span class="comment">/* residual I/O count */</span></span><br><span class="line"></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		bi_idx;		<span class="comment">/* current index into bvl_vec */</span></span><br><span class="line"></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>            bi_bvec_done;	<span class="comment">/* number of bytes completed in</span></span><br><span class="line"><span class="comment">						   current bvec */</span></span><br><span class="line">&#125; __packed;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">block_device</span> &#123;</span></span><br><span class="line">	<span class="type">sector_t</span>		bd_start_sect;</span><br><span class="line">	<span class="type">sector_t</span>		bd_nr_sectors;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">gendisk</span> *	<span class="title">bd_disk</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> *	<span class="title">bd_queue</span>;</span></span><br><span class="line">  <span class="type">bool</span>			bd_has_submit_bio;</span><br><span class="line">  ...</span><br><span class="line">&#125; __randomize_layout;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Try to put the fields that are referenced together in the same cacheline.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * If you modify this structure, make sure to update blk_rq_init() and</span></span><br><span class="line"><span class="comment"> * especially blk_mq_rq_ctx_init() to take care of the added fields.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">request</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> *<span class="title">q</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">bio</span> *<span class="title">bio</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">bio</span> *<span class="title">biotail</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">queuelist</span>;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">request</span> *<span class="title">rq_next</span>;</span></span><br><span class="line">	&#125;;</span><br><span class="line">	<span class="class"><span class="keyword">enum</span> <span class="title">mq_rq_state</span> <span class="title">state</span>;</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * The hash is used inside the scheduler, and killed once the</span></span><br><span class="line"><span class="comment">	 * request reaches the dispatch list. The ipi_list is only used</span></span><br><span class="line"><span class="comment">	 * to queue the request for softirq completion, which is long</span></span><br><span class="line"><span class="comment">	 * after the request has been unhashed (and even removed from</span></span><br><span class="line"><span class="comment">	 * the dispatch list).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">hlist_node</span> <span class="title">hash</span>;</span>	<span class="comment">/* merge hash */</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">llist_node</span> <span class="title">ipi_list</span>;</span></span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * The rb_node is only used inside the io scheduler, requests</span></span><br><span class="line"><span class="comment">	 * are pruned when moved to the dispatch queue. So let the</span></span><br><span class="line"><span class="comment">	 * completion_data share space with the rb_node.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">rb_node</span>;</span>	<span class="comment">/* sort/lookup */</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">bio_vec</span> <span class="title">special_vec</span>;</span></span><br><span class="line">		<span class="type">void</span> *completion_data;</span><br><span class="line">	&#125;;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * completion callback.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	rq_end_io_fn *end_io;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">request</span>		*<span class="title">last_merge</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">elevator_queue</span>	*<span class="title">elevator</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rq_qos</span>		*<span class="title">rq_qos</span>;</span></span><br><span class="line">	<span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">blk_mq_ops</span>	*<span class="title">mq_ops</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">queue_limits</span>	<span class="title">limits</span>;</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * for flush operations</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">blk_flush_queue</span>	*<span class="title">fq</span>;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * struct blk_mq_hw_ctx - State for a hardware queue facing the hardware</span></span><br><span class="line"><span class="comment"> * block device</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">blk_mq_hw_ctx</span> &#123;</span></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * @queue: Pointer to the request queue that owns this hardware context.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">request_queue</span>	*<span class="title">queue</span>;</span></span><br><span class="line">  	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * @dispatch_busy: Number used by blk_mq_update_dispatch_busy() to</span></span><br><span class="line"><span class="comment">	 * decide if the hw_queue is busy using Exponential Weighted Moving</span></span><br><span class="line"><span class="comment">	 * Average algorithm.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		dispatch_busy;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://s3.bmp.ovh/imgs/2021/09/09b73ed1c3ac78a1.webp" alt="bio逻辑架构"></p>
<h3 id="code-flow-in-block-layer"><a href="#code-flow-in-block-layer" class="headerlink" title="code flow in block layer"></a>code flow in block layer</h3><p><img src="https://pic2.zhimg.com/80/v2-5b898fe018554749f56c270e77261a4d_1440w.webp" alt="img"></p>
<p>Bio -&gt;  Request -&gt; plug request list -&gt; staging request queue in sheduler -&gt; hardware request queue</p>
<p>![Screenshot 2023-12-25 at 13.54.30](&#x2F;Users&#x2F;tashen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;Screenshot 2023-12-25 at 13.54.30.png)</p>
<p>![Screenshot 2023-12-25 at 13.57.23](&#x2F;Users&#x2F;tashen&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;Screenshot 2023-12-25 at 13.57.23.png)</p>
<p>These pictures records the total main code and function flow from the filessystem to block layer and to driver layder. It also prints the tracepoint mapping to the acation in output of the blktrace  where they trace from. By these tracepoint, we can understand the block io process flow more clearly. </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2024-03-06-IOCost-model-impact-cpu-soft-lockup/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2024-03-06-IOCost-model-impact-cpu-soft-lockup/" class="post-title-link" itemprop="url">IOCost model impact cpu soft lockup</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:51:59" itemprop="dateCreated datePublished" datetime="2024-03-10T12:51:59+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/system/" itemprop="url" rel="index"><span itemprop="name">system</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Reproduce"><a href="#Reproduce" class="headerlink" title="Reproduce"></a>Reproduce</h3><p><em>environment</em>:</p>
<p>5.15 kernel</p>
<p><em>way</em>:</p>
<p>Enable cgroup v2 and bfq, set bfq as scheduler on target deviceEnable io cost by &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;io.cost.qos, set cgroup io.weightStart two or more fio process to read or write on the target device, at least contains 1 direct and 1 buffer io, each one use different cgroupsWait 10-30 minutes</p>
<h3 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h3><p>Kernel Dump 1 (Set hardlockup_panic&#x3D;1 by sysctl):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">[ 1408.828715] Call Trace:</span><br><span class="line">[ 1408.828716]  &lt;TASK&gt;</span><br><span class="line">[ 1408.828718]  _raw_spin_lock_irq+0x26/0x30</span><br><span class="line">[ 1408.828722]  bfq_bio_merge+0x9f/0x160 [bfq]</span><br><span class="line">[ 1408.828727]  __blk_mq_sched_bio_merge+0x36/0x190</span><br><span class="line">[ 1408.828731]  blk_mq_submit_bio+0xd2/0x600</span><br><span class="line">[ 1408.828735]  __submit_bio+0x1dc/0x210</span><br><span class="line">[ 1408.828738]  submit_bio_noacct+0x263/0x2c0</span><br><span class="line">[ 1408.828741]  submit_bio+0x48/0x130</span><br><span class="line">[ 1408.828743]  iomap_submit_ioend.isra.0+0x52/0x80</span><br><span class="line">[ 1408.828745]  iomap_writepage_map+0x490/0x630</span><br><span class="line">[ 1408.828748]  iomap_do_writepage+0x75/0x230</span><br><span class="line">[ 1408.828750]  ? clear_page_dirty_for_io+0xdf/0x1d0</span><br><span class="line">[ 1408.828754]  write_cache_pages+0x184/0x450</span><br><span class="line">[ 1408.828756]  ? iomap_truncate_page+0x60/0x60</span><br><span class="line">[ 1408.828760]  iomap_writepages+0x20/0x40</span><br><span class="line">[ 1408.828762]  xfs_vm_writepages+0x84/0xb0 [xfs]</span><br><span class="line">[ 1408.828837]  do_writepages+0xc5/0x1c0</span><br><span class="line">[ 1408.828839]  ? __wb_calc_thresh+0x3e/0x120</span><br><span class="line">[ 1408.828842]  __writeback_single_inode+0x44/0x290</span><br><span class="line">[ 1408.828845]  writeback_sb_inodes+0x22d/0x4b0</span><br><span class="line">[ 1408.828849]  __writeback_inodes_wb+0x56/0xf0</span><br><span class="line">[ 1408.828852]  wb_writeback+0x1ce/0x290</span><br><span class="line">[ 1408.828855]  wb_workfn+0x31b/0x490</span><br><span class="line">[ 1408.828858]  ? psi_task_switch+0xc3/0x240</span><br><span class="line">[ 1408.828862]  process_one_work+0x22b/0x3d0</span><br><span class="line">[ 1408.828865]  worker_thread+0x4d/0x3f0</span><br><span class="line">[ 1408.828868]  ? process_one_work+0x3d0/0x3d0</span><br><span class="line">[ 1408.828870]  kthread+0x12a/0x150</span><br><span class="line">[ 1408.828872]  ? set_kthread_struct+0x40/0x40</span><br><span class="line">[ 1408.828874]  ret_from_fork+0x22/0x30</span><br><span class="line">[ 1408.828879]  &lt;/TASK&gt;</span><br><span class="line">[ 1408.829600] Kernel panic - not syncing: Hard LOCKUP</span><br><span class="line">[ 1408.829602] CPU: 26 PID: 0 Comm: swapper/26 Kdump: loaded Tainted: P          IOE K   5.15.0-26-generic #26</span><br><span class="line">[ 1408.829604] Hardware name: Dell Inc. PowerEdge C6420/0K2TT6, BIOS 2.4.8 11/27/2019</span><br><span class="line">[ 1408.829605] Call Trace:</span><br><span class="line">[ 1408.829606]  &lt;NMI&gt;</span><br><span class="line">[ 1408.829608]  dump_stack_lvl+0x4a/0x5f</span><br><span class="line">[ 1408.829615]  dump_stack+0x10/0x12</span><br><span class="line">[ 1408.829617]  panic+0x149/0x321</span><br><span class="line">[ 1408.829623]  nmi_panic.cold+0xc/0xc</span><br><span class="line">[ 1408.829626]  watchdog_overflow_callback.cold+0x5c/0x70</span><br><span class="line">[ 1408.829631]  __perf_event_overflow+0x57/0x100</span><br><span class="line">[ 1408.829634]  perf_event_overflow+0x14/0x20</span><br><span class="line">[ 1408.829637]  handle_pmi_common+0x1f3/0x2f0</span><br><span class="line">[ 1408.829643]  ? flush_tlb_one_kernel+0xe/0x20</span><br><span class="line">[ 1408.829647]  ? __set_pte_vaddr+0x37/0x40</span><br><span class="line">[ 1408.829650]  ? set_pte_vaddr_p4d+0x3d/0x50</span><br><span class="line">[ 1408.829652]  ? set_pte_vaddr+0x81/0xb0</span><br><span class="line">[ 1408.829653]  ? __native_set_fixmap+0x28/0x40</span><br><span class="line">[ 1408.829655]  ? native_set_fixmap+0x66/0x70</span><br><span class="line">[ 1408.829657]  ? ghes_copy_tofrom_phys+0x7c/0x120</span><br><span class="line">[ 1408.829663]  ? __ghes_peek_estatus.isra.0+0x4e/0xb0</span><br><span class="line">[ 1408.829666]  intel_pmu_handle_irq+0xf4/0x210</span><br><span class="line">[ 1408.829670]  perf_event_nmi_handler+0x2d/0x50</span><br><span class="line">[ 1408.829672]  nmi_handle+0x66/0x120</span><br><span class="line">[ 1408.829678]  default_do_nmi+0x45/0x110</span><br><span class="line">[ 1408.829681]  exc_nmi+0x175/0x190</span><br><span class="line">[ 1408.829683]  end_repeat_nmi+0x16/0x55</span><br><span class="line">[ 1408.829685] RIP: 0010:native_queued_spin_lock_slowpath+0x14f/0x220</span><br><span class="line">[ 1408.827472]  ? adjust_inuse_and_calc_cost+0x13a/0x250</span><br><span class="line">[ 1408.827475]  ioc_rqos_merge+0xef/0x260</span><br><span class="line">[ 1408.827478]  __rq_qos_merge+0x31/0x50</span><br><span class="line">[ 1408.827481]  bio_attempt_back_merge+0x43/0xd0</span><br><span class="line">[ 1408.827484]  blk_mq_sched_try_merge+0x147/0x1d0</span><br><span class="line">[ 1408.827486]  bfq_bio_merge+0xe2/0x160 [bfq]</span><br><span class="line">[ 1408.827491]  __blk_mq_sched_bio_merge+0x36/0x190</span><br><span class="line">[ 1408.827495]  blk_mq_submit_bio+0xd2/0x600</span><br><span class="line">[ 1408.827499]  __submit_bio+0x1dc/0x210</span><br><span class="line">[ 1408.827502]  ? get_user_pages_fast+0x24/0x40</span><br><span class="line">[ 1408.827507]  ? iov_iter_get_pages+0xc6/0x3f0</span><br><span class="line">[ 1408.827513]  submit_bio_noacct+0xac/0x2c0</span><br><span class="line">[ 1408.827516]  submit_bio+0x48/0x130</span><br><span class="line">[ 1408.827518]  iomap_dio_submit_bio+0x79/0x80</span><br><span class="line">[ 1408.827524]  iomap_dio_bio_iter+0x2d7/0x4a0</span><br><span class="line">[ 1408.827528]  __iomap_dio_rw+0x531/0x7c0</span><br><span class="line">[ 1408.827532]  iomap_dio_rw+0xe/0x30</span><br><span class="line">[ 1408.827535]  xfs_file_dio_write_aligned+0xa0/0x110 [xfs]</span><br><span class="line">[ 1408.827647]  xfs_file_write_iter+0x101/0x1a0 [xfs]</span><br><span class="line">[ 1408.827736]  aio_write+0x116/0x210</span><br><span class="line">[ 1408.827740]  ? update_load_avg+0x7c/0x640</span><br><span class="line">[ 1408.827744]  ? set_next_entity+0xb7/0x200</span><br><span class="line">[ 1408.827747]  __io_submit_one.constprop.0+0x40e/0x720</span><br><span class="line">[ 1408.827749]  ? __io_submit_one.constprop.0+0x40e/0x720</span><br><span class="line">[ 1408.827752]  ? __check_object_size+0x5d/0x150</span><br><span class="line">[ 1408.827755]  ? _copy_to_user+0x20/0x30</span><br><span class="line">[ 1408.827760]  ? aio_read_events+0x210/0x320</span><br><span class="line">[ 1408.827762]  io_submit_one+0xe3/0x550</span><br><span class="line">[ 1408.827764]  ? io_submit_one+0xe3/0x550</span><br><span class="line">[ 1408.827766]  ? audit_filter_rules.constprop.0+0x3b1/0x12e0</span><br><span class="line">[ 1408.827772]  __x64_sys_io_submit+0x8d/0x180</span><br><span class="line">[ 1408.827775]  ? syscall_trace_enter.isra.0+0x146/0x1c0</span><br><span class="line">[ 1408.827779]  do_syscall_64+0x5c/0xc0</span><br><span class="line">[ 1408.827782]  ? exit_to_user_mode_prepare+0x3d/0x1c0</span><br><span class="line">[ 1408.827785]  ? syscall_exit_to_user_mode+0x27/0x50</span><br><span class="line">[ 1408.827788]  ? do_syscall_64+0x69/0xc0</span><br><span class="line">[ 1408.827790]  ? irqentry_exit+0x19/0x30</span><br><span class="line">[ 1408.827793]  ? sysvec_call_function_single+0x4e/0x90</span><br><span class="line">[ 1408.827795]  ? asm_sysvec_call_function_single+0xa/0x20</span><br><span class="line">[ 1408.827799]  entry_SYSCALL_64_after_hwframe+0x44/0xae</span><br></pre></td></tr></table></figure>





<p>Kernel dump 2 :</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">[60977.577690] BUG: spinlock recursion on CPU#21, fio/11770</span><br><span class="line">[60977.583007]  lock: 0xffff92600e348c20, .magic: dead4ead, .owner: fio/11770, .owner_cpu: 21</span><br><span class="line">[60977.591275] CPU: 21 PID: 11770 Comm: fio Kdump: loaded Not tainted 5.15.0-26-generic #26</span><br><span class="line">[60977.599362] Hardware name: Supermicro SYS-6029TP-H-EI012/X11DPT-PS-EI012, BIOS 1.0.9.0 01/31/2018</span><br><span class="line">[60977.608229] Call Trace:</span><br><span class="line">[60977.610682]  &lt;IRQ&gt;</span><br><span class="line">[60977.612700]  dump_stack_lvl+0x58/0x7d</span><br><span class="line">[60977.616367]  dump_stack+0x10/0x12</span><br><span class="line">[60977.619687]  spin_dump.cold+0x24/0x39</span><br><span class="line">[60977.623359]  do_raw_spin_lock+0x9a/0xd0</span><br><span class="line">[60977.627198]  _raw_spin_lock_irqsave+0x7d/0x80</span><br><span class="line">[60977.631561]  bfq_finish_requeue_request+0x55/0x540 [bfq]</span><br><span class="line">[60977.636874]  blk_mq_free_request+0x3e/0x160</span><br><span class="line">[60977.641058]  __blk_mq_end_request+0x102/0x110</span><br><span class="line">[60977.645419]  scsi_end_request+0xce/0x190</span><br><span class="line">[60977.649345]  scsi_io_completion+0x7e/0x5d0</span><br><span class="line">[60977.653442]  scsi_finish_command+0xca/0x100</span><br><span class="line">[60977.657629]  scsi_complete+0x74/0xe0</span><br><span class="line">[60977.661212]  blk_complete_reqs+0x3b/0x50</span><br><span class="line">[60977.665135]  blk_done_softirq+0x1d/0x20</span><br><span class="line">[60977.668975]  __do_softirq+0xf7/0x31e</span><br><span class="line">[60977.672554]  irq_exit_rcu+0x79/0xa0</span><br><span class="line">[60977.676044]  sysvec_call_function_single+0x7c/0x90</span><br><span class="line">[60977.680837]  &lt;/IRQ&gt;</span><br><span class="line">[60977.682945]  &lt;TASK&gt;</span><br><span class="line">[60977.685051]  asm_sysvec_call_function_single+0x12/0x20</span><br><span class="line">[60977.690189] RIP: 0010:_raw_spin_unlock_irq+0x2a/0x30</span><br><span class="line">[60977.695155] Code: 0f 1f 44 00 00 55 48 89 e5 41 54 49 89 fc 48 8d 7f 18 48 8b 75 08 e8 75 6f 3d ff 4c 89 e7 e8 8d b0 3d ff fb 66 0f 1f 44 00 00 &lt;41&gt; 5c 5d c3 66 90 0f 1f 44 00 00 55 48 89 e5 41 54 49 89 fc 48 8d</span><br><span class="line">[60977.713902] RSP: 0018:ffffa0781992b670 EFLAGS: 00000246</span><br><span class="line">[60977.719128] RAX: 0000000000000015 RBX: 00000000001d9281 RCX: 0000000036d7555b</span><br><span class="line">[60977.726260] RDX: 000000007a3bfa68 RSI: ffff9260bca80d48 RDI: ffff92600fd9f0e0</span><br><span class="line">[60977.733392] RBP: ffffa0781992b678 R08: 00000000ffffffff R09: 00000000ffffffff</span><br><span class="line">[60977.740527] R10: 0000000000000001 R11: ffff9231c6d2cc00 R12: ffff92600fd9f0e0</span><br><span class="line">[60977.747661] R13: ffffa0781992b710 R14: 0000000000000001 R15: 000000000019007e</span><br><span class="line">[60977.754794]  adjust_inuse_and_calc_cost+0x164/0x250</span><br><span class="line">[60977.759673]  ioc_rqos_merge+0xef/0x260</span><br><span class="line">[60977.763425]  __rq_qos_merge+0x31/0x50</span><br><span class="line">[60977.767091]  bio_attempt_back_merge+0x64/0xf0</span><br><span class="line">[60977.771451]  blk_mq_sched_try_merge+0x147/0x1d0</span><br><span class="line">[60977.775982]  bfq_bio_merge+0xe2/0x150 [bfq]</span><br><span class="line">[60977.780168]  __blk_mq_sched_bio_merge+0x36/0x1b0</span><br><span class="line">[60977.784790]  blk_mq_submit_bio+0xd5/0x690</span><br><span class="line">[60977.788803]  __submit_bio+0x23d/0x270</span><br><span class="line">[60977.792465]  ? wake_up_page_bit+0xd3/0x100</span><br><span class="line">[60977.796568]  submit_bio_noacct+0x26c/0x2d0</span><br><span class="line">[60977.800664]  ? wake_up_page_bit+0xd3/0x100</span><br><span class="line">[60977.804764]  submit_bio+0x48/0x140</span><br><span class="line">[60977.808171]  iomap_submit_ioend.isra.0+0x52/0x80</span><br><span class="line">[60977.812790]  iomap_writepage_map+0x490/0x630</span><br><span class="line">[60977.817065]  iomap_do_writepage+0x8c/0x260</span><br><span class="line">[60977.821161]  ? clear_page_dirty_for_io+0x113/0x220</span><br><span class="line">[60977.825955]  write_cache_pages+0x19e/0x460</span><br><span class="line">[60977.830054]  ? iomap_truncate_page+0x60/0x60</span><br><span class="line">[60977.834330]  iomap_writepages+0x20/0x40</span><br><span class="line">[60977.838167]  xfs_vm_writepages+0x85/0xb0 [xfs]</span><br><span class="line">[60977.842718]  do_writepages+0xc6/0x1c0</span><br><span class="line">[60977.846384]  ? _raw_spin_unlock+0x23/0x30</span><br><span class="line">[60977.850398]  filemap_fdatawrite_wbc+0x7d/0xc0</span><br><span class="line">[60977.854756]  __filemap_fdatawrite_range+0x54/0x70</span><br><span class="line">[60977.859463]  generic_fadvise+0x299/0x2c0</span><br><span class="line">[60977.863387]  xfs_file_fadvise+0x23/0x80 [xfs]</span><br><span class="line">[60977.867807]  vfs_fadvise+0x1e/0x30</span><br><span class="line">[60977.871214]  ksys_fadvise64_64+0x41/0x80</span><br><span class="line">[60977.875140]  ? syscall_trace_enter.isra.0+0x16b/0x1e0</span><br><span class="line">[60977.880194]  __x64_sys_fadvise64+0x1e/0x30</span><br><span class="line">[60977.884291]  do_syscall_64+0x5c/0xc0</span><br><span class="line">[60977.887870]  ? irqentry_exit_to_user_mode+0x9/0x20</span><br><span class="line">[60977.892665]  ? irqentry_exit+0x19/0x30</span><br><span class="line">[60977.896416]  ? exc_page_fault+0x94/0x1b0</span><br><span class="line">[60977.900343]  ? asm_exc_page_fault+0x8/0x30</span><br><span class="line">[60977.904444]  entry_SYSCALL_64_after_hwframe+0x44/0xae</span><br><span class="line">[60977.909496] RIP: 0033:0x7f16f2c07d3e</span><br><span class="line">[60977.913076] Code: 10 10 00 f7 d8 64 89 02 b8 ff ff ff ff eb b3 e8 28 d8 01 00 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 41 89 ca b8 dd 00 00 00 0f 05 &lt;89&gt; c2 f7 da 3d 00 f0 ff ff b8 00 00 00 00 0f 47 c2 c3 41 57 41 56</span><br><span class="line">[60977.931819] RSP: 002b:00007ffd83ec8338 EFLAGS: 00000246 ORIG_RAX: 00000000000000dd</span><br><span class="line">[60977.939388] RAX: ffffffffffffffda RBX: 00007f16effca890 RCX: 00007f16f2c07d3e</span><br><span class="line">[60977.946518] RDX: 0000000280000000 RSI: 0000000000000000 RDI: 0000000000000006</span><br><span class="line">[60977.953652] RBP: 0000000000000000 R08: 00007f16e8f2b028 R09: 0000000000000000</span><br><span class="line">[60977.960784] R10: 0000000000000004 R11: 0000000000000246 R12: 0000000280000000</span><br><span class="line">[60977.967918] R13: 00007f16e8c16c80 R14: 00007f16effca890 R15: 00007f16e8c16c80</span><br><span class="line">[60977.975053]  &lt;/TASK&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>Kernel dump 3 (enable lockdep):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">[ 4398.422037] WARNING: inconsistent lock state</span><br><span class="line">[ 4398.426311] 5.15.0-26-generic #26 Not tainted</span><br><span class="line">[ 4398.430666] --------------------------------</span><br><span class="line">[ 4398.434939] inconsistent &#123;IN-HARDIRQ-W&#125; -&gt; &#123;HARDIRQ-ON-W&#125; usage.</span><br><span class="line">[ 4398.440947] fio/156503 [HC0[0]:SC0[0]:HE0:SE1] takes:</span><br><span class="line">[ 4398.445997] ffff8b5bd4771c38 (&amp;bfqd-&gt;lock)&#123;?.-.&#125;-&#123;2:2&#125;, at: bfq_bio_merge+0x9f/0x150 [bfq]</span><br><span class="line">[ 4398.454265] &#123;IN-HARDIRQ-W&#125; state was registered at:</span><br><span class="line">[ 4398.459148]   lock_acquire+0xd8/0x300</span><br><span class="line">[ 4398.462823]   _raw_spin_lock_irqsave+0x52/0xa0</span><br><span class="line">[ 4398.467279]   bfq_idle_slice_timer+0x2d/0xc0 [bfq]</span><br><span class="line">[ 4398.472079]   __hrtimer_run_queues+0x8b/0x420</span><br><span class="line">[ 4398.476438]   hrtimer_interrupt+0x109/0x230</span><br><span class="line">[ 4398.480621]   __sysvec_apic_timer_interrupt+0x78/0x1f0</span><br><span class="line">[ 4398.485761]   sysvec_apic_timer_interrupt+0x77/0x90</span><br><span class="line">[ 4398.490640]   asm_sysvec_apic_timer_interrupt+0x12/0x20</span><br><span class="line">[ 4398.495868]   lock_is_held_type+0x115/0x150</span><br><span class="line">[ 4398.500054]   rcu_read_lock_sched_held+0x5a/0x90</span><br><span class="line">[ 4398.504673]   lock_acquire+0x19f/0x300</span><br><span class="line">[ 4398.508426]   process_one_work+0x28d/0x5d0</span><br><span class="line">[ 4398.512525]   worker_thread+0x4a/0x3d0</span><br><span class="line">[ 4398.516276]   kthread+0x141/0x160</span><br><span class="line">[ 4398.519597]   ret_from_fork+0x22/0x30</span><br><span class="line">[ 4398.523289] irq event stamp: 1141506</span><br><span class="line">[ 4398.526869] hardirqs last  enabled at (1141505): [&lt;ffffffff880849b1&gt;] _raw_spin_unlock_irqrestore+0x51/0x70</span><br><span class="line">[ 4398.536601] hardirqs last disabled at (1141506): [&lt;ffffffff88084744&gt;] _raw_spin_lock_irq+0x74/0x90</span><br><span class="line">[ 4398.545556] softirqs last  enabled at (1139712): [&lt;ffffffff884002f5&gt;] __do_softirq+0x2f5/0x4d3</span><br><span class="line">[ 4398.554160] softirqs last disabled at (1139699): [&lt;ffffffff872c9556&gt;] irq_exit_rcu+0x96/0xc0</span><br><span class="line">[ 4398.562594] </span><br><span class="line">               other info that might help us debug this:</span><br><span class="line">[ 4398.569121]  Possible unsafe locking scenario:</span><br><span class="line">               </span><br><span class="line">[ 4398.575041]        CPU0</span><br><span class="line">[ 4398.577494]        ----</span><br><span class="line">[ 4398.579947]   lock(&amp;bfqd-&gt;lock);</span><br><span class="line">[ 4398.583188]   &lt;Interrupt&gt;</span><br><span class="line">[ 4398.585813]     lock(&amp;bfqd-&gt;lock);</span><br><span class="line">[ 4398.589219] </span><br><span class="line">                *** DEADLOCK ***</span><br><span class="line">               </span><br><span class="line">[ 4398.595137] 2 locks held by fio/156503:</span><br><span class="line">[ 4398.598978]  #0: ffff8b5c653c4e28 (&amp;sb-&gt;s_type-&gt;i_mutex_key#14)&#123;++++&#125;-&#123;3:3&#125;, at: xfs_ilock+0x104/0x1b0 [xfs]</span><br><span class="line">[ 4398.608937]  #1: ffff8b5bd4771c38 (&amp;bfqd-&gt;lock)&#123;?.-.&#125;-&#123;2:2&#125;, at: bfq_bio_merge+0x9f/0x150 [bfq]</span><br><span class="line">[ 4398.617637] </span><br><span class="line">               stack backtrace:</span><br><span class="line">[ 4398.621999] CPU: 19 PID: 156503 Comm: fio Kdump: loaded Not tainted 5.15.0-26-generic #26</span><br><span class="line">[ 4398.630170] Hardware name: Supermicro SYS-6029TP-H-EI012/X11DPT-PS-EI012, BIOS 1.0.9.0 01/31/2018</span><br><span class="line">[ 4398.639036] Call Trace:</span><br><span class="line">[ 4398.641488]  &lt;TASK&gt;</span><br><span class="line">[ 4398.643596]  dump_stack_lvl+0x6e/0x9c</span><br><span class="line">[ 4398.647284]  dump_stack+0x10/0x12</span><br><span class="line">[ 4398.650605]  print_usage_bug.part.0+0x18e/0x19d</span><br><span class="line">[ 4398.655138]  mark_lock_irq.cold+0x11/0x2c</span><br><span class="line">[ 4398.659151]  ? stack_trace_save+0x4c/0x70</span><br><span class="line">[ 4398.663164]  ? save_trace+0x45/0x2f0</span><br><span class="line">[ 4398.666742]  mark_lock.part.0+0x11f/0x220</span><br><span class="line">[ 4398.670756]  mark_held_locks+0x54/0x80</span><br><span class="line">[ 4398.674510]  ? adjust_inuse_and_calc_cost+0x164/0x2c0</span><br><span class="line">[ 4398.679563]  lockdep_hardirqs_on_prepare+0x7f/0x1c0</span><br><span class="line">[ 4398.680859] patch_est_timer: disagrees about version of symbol module_layout</span><br><span class="line">[ 4398.684449]  ? _raw_spin_unlock_irq+0x28/0x40</span><br><span class="line">[ 4398.695856]  trace_hardirqs_on+0x21/0xe0</span><br><span class="line">[ 4398.699791]  _raw_spin_unlock_irq+0x28/0x40</span><br><span class="line">[ 4398.703974]  adjust_inuse_and_calc_cost+0x164/0x2c0</span><br><span class="line">[ 4398.708858]  ioc_rqos_merge+0xef/0x280</span><br><span class="line">[ 4398.712608]  __rq_qos_merge+0x31/0x50</span><br><span class="line">[ 4398.716272]  bio_attempt_back_merge+0x63/0x160</span><br><span class="line">[ 4398.720722]  blk_mq_sched_try_merge+0x147/0x1d0</span><br><span class="line">[ 4398.725256]  bfq_bio_merge+0xe2/0x150 [bfq]</span><br><span class="line">[ 4398.729448]  __blk_mq_sched_bio_merge+0x36/0x1b0</span><br><span class="line">[ 4398.734069]  blk_mq_submit_bio+0xd5/0x900</span><br><span class="line">[ 4398.738082]  __submit_bio+0x307/0x340</span><br><span class="line">[ 4398.741746]  ? get_user_pages_fast+0x24/0x40</span><br><span class="line">[ 4398.746018]  ? iov_iter_get_pages+0xc6/0x400</span><br><span class="line">[ 4398.750292]  submit_bio_noacct+0x26c/0x2d0</span><br><span class="line">[ 4398.754393]  submit_bio+0x48/0x140</span><br><span class="line">[ 4398.757797]  iomap_dio_submit_bio+0x7c/0x90</span><br><span class="line">[ 4398.761983]  iomap_dio_bio_iter+0x2da/0x4b0</span><br><span class="line">[ 4398.766172]  __iomap_dio_rw+0x514/0x830</span><br><span class="line">[ 4398.770012]  iomap_dio_rw+0xe/0x30</span><br><span class="line">[ 4398.773413]  xfs_file_dio_write_aligned+0xb9/0x1a0 [xfs]</span><br><span class="line">[ 4398.778821]  ? sched_clock_cpu+0x12/0xe0</span><br><span class="line">[ 4398.782749]  xfs_file_write_iter+0x101/0x1a0 [xfs]</span><br><span class="line">[ 4398.787613]  aio_write+0x131/0x310</span><br><span class="line">[ 4398.791019]  ? __fget_files+0xcf/0x1c0</span><br><span class="line">[ 4398.794771]  __io_submit_one.constprop.0+0x43a/0x570</span><br><span class="line">[ 4398.799740]  ? __io_submit_one.constprop.0+0x43a/0x570</span><br><span class="line">[ 4398.804885]  ? sched_clock_cpu+0x12/0xe0</span><br><span class="line">[ 4398.808819]  ? io_submit_one+0xd9/0x870</span><br><span class="line">[ 4398.812671]  io_submit_one+0x142/0x870</span><br><span class="line">[ 4398.816429]  ? io_submit_one+0x142/0x870</span><br><span class="line">[ 4398.820373]  __x64_sys_io_submit+0x97/0x2a0</span><br><span class="line">[ 4398.824569]  ? syscall_trace_enter.isra.0+0x186/0x250</span><br><span class="line">[ 4398.829632]  do_syscall_64+0x5c/0xc0</span><br><span class="line">[ 4398.833217]  ? __x64_sys_io_cancel+0x250/0x250</span><br><span class="line">[ 4398.837660]  ? do_syscall_64+0x5c/0xc0</span><br><span class="line">[ 4398.841412]  ? do_syscall_64+0x69/0xc0</span><br><span class="line">[ 4398.845165]  ? do_syscall_64+0x69/0xc0</span><br><span class="line">[ 4398.848921]  ? sysvec_call_function_single+0x4e/0x90</span><br><span class="line">[ 4398.853884]  ? asm_sysvec_call_function_single+0xa/0x20</span><br><span class="line">[ 4398.859110]  entry_SYSCALL_64_after_hwframe+0x44/0xae</span><br><span class="line">[ 4398.864165] RIP: 0033:0x7fd43e139697</span><br><span class="line">[ 4398.867746] Code: 00 75 10 8b 47 0c 39 47 08 74 10 0f 1f 84 00 00 00 00 00 e9 bb ff ff ff 0f 1f 00 31 c0 c3 0f 1f 44 00 00 b8 d1 00 00 00 0f 05 &lt;c3&gt; 0f 1f 84 00 00 00 00 00 b8 d2 00 00 00 0f 05 c3 0f 1f 84 00 00</span><br><span class="line">[ 4398.886488] RSP: 002b:00007fd439a49cc8 EFLAGS: 00000202 ORIG_RAX: 00000000000000d1</span><br><span class="line">[ 4398.894057] RAX: ffffffffffffffda RBX: 00007fd43a24c000 RCX: 00007fd43e139697</span><br><span class="line">[ 4398.901187] RDX: 00007fd43400d530 RSI: 0000000000000001 RDI: 00007fd43eb24000</span><br><span class="line">[ 4398.908323] RBP: 00007fd43a24c000 R08: 00007fd43a7051f0 R09: 00000000000001f0</span><br><span class="line">[ 4398.915454] R10: 0000000004455000 R11: 0000000000000202 R12: 00007fd43400ccf0</span><br><span class="line">[ 4398.922587] R13: 00007fd43400d740 R14: 00007fd43400d530 R15: 00007fd43a251210</span><br><span class="line">[ 4398.929725]  &lt;/TASK&gt;</span><br></pre></td></tr></table></figure>



<p>Lock chain:</p>
<ol>
<li>bfq_bio_merge:</li>
</ol>
<p>​	spin_lock_irq(&amp;bfqd-&gt;lock);</p>
<p>​	blk_mq_sched_try_merge:</p>
<p>​		adjust_inuse_and_calc_cost:</p>
<p>​				spin_lock_irq(&amp;ioc-&gt;lock);</p>
<p>​				spin_unlock_irq(&amp;ioc-&gt;lock);</p>
<ol start="2">
<li>bfq_finish_requeue_request:</li>
</ol>
<p>​		spin_lock_irqsave(&amp;bfqd-&gt;lock, flags);</p>
<p>​		…</p>
<p>​		spin_unlock_irqrestore(&amp;bfqd-&gt;lock, flags);</p>
<p><img src="https://lh7-us.googleusercontent.com/bq2FPR6rf3vTi3qwBroUf_ukX2q8_kuRj8GbANgmURAwdcfd3c6QBivBGFvtvvADlqdTU4CbjvhIBrHzJefKR8UpE5WR7A0jZ7tFH5odAsfF8JjofHbi2vq8AFHgUT6cdfmcOxm0Tc0gyZCdXJGYfog" alt="img"></p>
<p>There is a process running on cpu and hold a lock spin_lock_irq(&amp;bfqd-&gt;lock), then the process to hold the second lock by spin_lock_irq(&amp;ioc-&gt;lock), after finish calculation, the process release the second lock spin_unlock_irq(&amp;ioc-&gt;lock), at this time the kernel allow irq, and a irq preempts the cpu and when run into function <em>bfq_finish_requeue_request,</em> it try to hold the first lock by spin_lock_irqsave(&amp;bfqd-&gt;lock, flags), but it is still hold by original process, so it is deadlock. The locked module can detect this case and reprot the risk into dmesg (stack 3). </p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>This kernel patch fix the issue in kernel 6.3.13 version:</p>
<p><em><a target="_blank" rel="noopener" href="https://lwn.net/Articles/937933/">https://lwn.net/Articles/937933/</a></em></p>
<p><a target="_blank" rel="noopener" href="https://www.spinics.net/lists/stable/msg669695.html"><em>https://www.spinics.net/lists/stable/msg669695.html</em></a></p>
<p>In this patch, the fix is using <em>spin_lock_irqsave</em> to replace <em>spin_lock_irq</em> in the function of “<em>adjust_inuse_and_calc_cost</em>” to block the irq when unlocked.</p>
<p>We will cherry-pick the patch into our 5.15 kernel.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2018-10-12-raid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2018-10-12-raid/" class="post-title-link" itemprop="url">raid</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:35:02" itemprop="dateCreated datePublished" datetime="2024-03-10T12:35:02+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/storage/" itemprop="url" rel="index"><span itemprop="name">storage</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RAID"><a href="#RAID" class="headerlink" title="RAID"></a>RAID</h1><p>RAID是用于增加数据存储的性能和可靠性的技术。全程为Redundant Array of Inexpensive Disks（廉价磁盘冗余阵列）</p>
<ul>
<li>RAID 0 - strping</li>
<li>RAID 1 - mirroring</li>
<li>RAID 5 - striping with parity</li>
<li>RAID 6 - striping with double parity</li>
<li>RAID 10 - combining mirroring and striping</li>
</ul>
<h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>mdadm目前是Linux标准RAID管理工具, 能够支持多种模式，可以对RAID进行创建，管理，添加和移除设备等，还能查看RAID设备的详细信息。功能非常强大。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$yum install mdadm -y</span><br><span class="line">$git clone git://neil.brown.name/mdadm</span><br></pre></td></tr></table></figure>



<p>devicemapper 也能创建RAID设备.</p>
<p>用dd创建4个镜像作为loop设备</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$dd if=/dev/zero of=disk1.img bs=512 count=4096000</span><br><span class="line">$losetup /dev/loop2 disk1.img</span><br><span class="line">...</span><br></pre></td></tr></table></figure>



<h3 id="RAID-level-0-–-Striping"><a href="#RAID-level-0-–-Striping" class="headerlink" title="RAID level 0 – Striping"></a>RAID level 0 – Striping</h3><p><a target="_blank" rel="noopener" href="http://www.prepressure.com/images/raid-level-0-striping.svg"><img src="http://www.prepressure.com/images/raid-level-0-striping.svg" alt="image"></a></p>
<p>Raid 0 将数据进行条带化，同时向多个磁盘(至少2个)写数据.不做数据冗余，理想的情况，每个磁盘使用单独的控制器管理。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li><p>读写性能好，没有数据冗余。</p>
</li>
<li><p>所有磁盘都有用.</p>
</li>
<li><p>容易实现.</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4></li>
<li><p>没有容错机制</p>
<h4 id="mdadm"><a href="#mdadm" class="headerlink" title="mdadm"></a>mdadm</h4></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mdadm --create --verbose /dev/md0 --level=stripe --raid-devices=2 /dev/loop2 /dev/loop3</span><br><span class="line">mdadm --manage --stop /dev/md0</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$fdisk -l</span><br><span class="line">...</span><br><span class="line">Disk /dev/md0: 4192 MB, 4192206848 bytes, 8187904 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 524288 bytes / 1048576 bytes</span><br><span class="line"></span><br><span class="line">$lsblk</span><br><span class="line">NAME  MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT</span><br><span class="line">...</span><br><span class="line">loop2  7:2    0     2G  0 loop  </span><br><span class="line">└─md0  9:0    0   3.9G  0 raid0 </span><br><span class="line">loop3  7:3    0     2G  0 loop  </span><br><span class="line">└─md0  9:0    0   3.9G  0 raid0</span><br></pre></td></tr></table></figure>



<h4 id="devicemapper"><a href="#devicemapper" class="headerlink" title="devicemapper"></a>devicemapper</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 创建4设备组成的raid0设备，16384000是4个设备总的Sector数量， 0 是每个设备的偏移量</span><br><span class="line">$dmsetup create test-raid0 --table &#x27;0 16384000 striped 4 128 /dev/loop4 0 /dev/loop5 0 /dev/loop6 0 /dev/loop7 0&#x27;</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$lsblk</span><br><span class="line">loop4         7:4    0     2G  0 loop  </span><br><span class="line">└─test-raid0  253:23   0   7.8G  0 dm    </span><br><span class="line">loop5         7:5    0     2G  0 loop  </span><br><span class="line">└─test-raid0  53:23   0   7.8G  0 dm    </span><br><span class="line">loop6         7:6    0     2G  0 loop  </span><br><span class="line">└─test-raid0  253:23   0   7.8G  0 dm    </span><br><span class="line">loop7         7:7    0     2G  0 loop  </span><br><span class="line">└─test-raid0  253:23   0   7.8G  0 dm</span><br><span class="line"></span><br><span class="line">$fdisk -l</span><br><span class="line">...</span><br><span class="line">Disk /dev/mapper/test-raid0: 8388 MB, 8388608000 bytes, 16384000 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 65536 bytes / 262144 bytes</span><br><span class="line"></span><br><span class="line">$dmsetup status test-raid0</span><br><span class="line">0 16384000 striped 4 7:4 7:5 7:6 7:7 1 AAAA</span><br></pre></td></tr></table></figure>



<h3 id="RAID-level-1-–-Mirroring"><a href="#RAID-level-1-–-Mirroring" class="headerlink" title="RAID level 1 – Mirroring"></a>RAID level 1 – Mirroring</h3><h3 id=""><a href="#" class="headerlink" title=""></a><a target="_blank" rel="noopener" href="http://www.prepressure.com/images/raid-level-1-mirroring.svg"><img src="http://www.prepressure.com/images/raid-level-1-mirroring.svg" alt="image"></a></h3><p>RAID 1 数据存储两次，如果一个drive挂了，控制器会使用另外一个drive或者直接拷贝另一个drive的数据给它。</p>
<p>RAID 1的优缺点很明显，值得一提的的是，它不能保证热交换磁盘，也就是说，当一块盘坏了之后，需要将计算机停机，然后才能更换磁盘。</p>
<h4 id="mdadm-1"><a href="#mdadm-1" class="headerlink" title="mdadm"></a>mdadm</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$mdadm --create --verbose /dev/md0 --level=mirror --raid-devices=2 /dev/loop2 /dev/loop3</span><br></pre></td></tr></table></figure>

<h4 id="devicemapper-1"><a href="#devicemapper-1" class="headerlink" title="devicemapper"></a>devicemapper</h4><p>devicemapper中mirror与raid1是有差别的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 4096000是单个设备的sector数量，因为mirror没有扩大容量，2是设备数量， - 表示没有metadata 设备</span><br><span class="line">$dmsetup create test-raid1 --table &#x27;0 4096000 raid raid1 3 0 region_size 1024 2 - /dev/loop4 - /dev/loop5&#x27;</span><br><span class="line">//下面的是有metadata设备的raid1创建</span><br><span class="line">$dmsetup create test-raid1 --table &#x27;0 4096000 raid raid1 3 0 region_size 1024 2 /dev/loop4 /dev/loop5 /dev/loop6 /dev/loop7&#x27;</span><br><span class="line"></span><br><span class="line">$dmsetup status test-raid1</span><br><span class="line">0 4096000 raid raid1 2 AA 4096000/4096000 idle 0</span><br></pre></td></tr></table></figure>



<h3 id="RAID-level-5"><a href="#RAID-level-5" class="headerlink" title="RAID level 5"></a>RAID level 5</h3><p>最为普遍的RAID方式。要求至少3个drive，其中一个drive的一个磁盘作为奇偶校验盘，其他块做striping。所有奇偶校验盘会广泛分布在所有drive上。当有某个盘挂掉后，可以利用其他块以及奇偶校验盘来恢复数据，但如果同一个块中有两个设备挂掉，那么整个RAID就挂了。也就是说，RAID5能够支持单drive失败。<a target="_blank" rel="noopener" href="http://www.prepressure.com/images/raid-level-5-striping-with-parity.svg"><br><img src="http://www.prepressure.com/images/raid-level-5-striping-with-parity.svg" alt="image"></a></p>
<p>RAID5的优点是兼顾了读写性能和安全性，能够支持单drive的失败情况。缺点在于实现比较复杂，恢复数据比较慢，如果在恢复的过程中其他drive也发生故障，那么整个RAID就挂了。</p>
<h4 id="mdadm-2"><a href="#mdadm-2" class="headerlink" title="mdadm"></a>mdadm</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// spare device指定备用磁盘，创建3块盘的RAID5</span><br><span class="line">$mdadm --create --verbose /dev/md1 --level=5 --raid-devices=3 /dev/loop4 /dev/loop5 /dev/loop6 --spare-devices=1 /dev/loop7</span><br></pre></td></tr></table></figure>

<p>查看信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$mdadm --detail /dev/md1/dev/md1:        Version : 1.2  Creation Time : Tue Mar  7 16:57:39 2017     Raid Level : raid5     Array Size : 4093952 (3.90 GiB 4.19 GB)  Used Dev Size : 2046976 (1999.34 MiB 2096.10 MB)   Raid Devices : 3  Total Devices : 4    Persistence : Superblock is persistent    Update Time : Tue Mar  7 16:57:57 2017          State : clean  Active Devices : 3Working Devices : 4 Failed Devices : 0  Spare Devices : 1         Layout : left-symmetric     Chunk Size : 512K           Name : st-integrat-node00:1  (local to host st-integrat-node00)           UUID : 071d2e75:2029e9a2:2e427dd9:d2ab804f         Events : 18    Number   Major   Minor   RaidDevice State       0       7        4        0      active sync   /dev/loop4       1       7        5        1      active sync   /dev/loop5       4       7        6        2      active sync   /dev/loop6       3       7        7        -      spare   /dev/loop7`</span><br></pre></td></tr></table></figure>

<h4 id="device-mapper"><a href="#device-mapper" class="headerlink" title="device-mapper"></a>device-mapper</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 这里创建了没有metadata设备的4个设备的raid5，因此大小是3倍磁盘扇区大小，有一个作为奇偶校验。 </span><br><span class="line">$dmsetup create test-raid5 --table &#x27;0 12288000 raid raid5_ls 3 64 region_size 1024 4 - /dev/loop4 - /dev/loop5 - /dev/loop6 - /dev/loop7&#x27;</span><br><span class="line">// metadata设备的创建过程和前面RAID1的类似，这里略过。</span><br><span class="line">//devicemapper还可以创建degraded RAID5,只需将最后一个设备置为 - 即可。</span><br><span class="line">$dmsetup create test-raid5 --table &#x27;0 12288000 raid raid5_ls 3 64 region_size 1024 4 - /dev/loop4 - /dev/loop5 - - -</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// resync 表示正在同步， 4096000/4096000表示全部同步完成。</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">dmsetup status test-raid5</span></span><br><span class="line">0 12288000 raid raid5_ls 4 aaaa 2048064/4096000 resync 0</span><br><span class="line">0 12288000 raid raid5_ls 4 AAAA 4096000/4096000 idle 0</span><br><span class="line">//同步过程中也是可以删除设备的</span><br></pre></td></tr></table></figure>

<h3 id="RAID-level-6-–-Striping-with-double-parity"><a href="#RAID-level-6-–-Striping-with-double-parity" class="headerlink" title="RAID level 6 – Striping with double parity"></a>RAID level 6 – Striping with double parity</h3><p><a target="_blank" rel="noopener" href="http://www.prepressure.com/images/raid-level-6-striping-with-dual-parity.svg"><img src="http://www.prepressure.com/images/raid-level-6-striping-with-dual-parity.svg" alt="image"></a><br>RAID6改进了RAID5，使用了两块奇偶校验盘，<br>RAID6的创建过程和RAID5相似.</p>
<h3 id="RAID-level-10-–-combining-RAID-1-RAID-0"><a href="#RAID-level-10-–-combining-RAID-1-RAID-0" class="headerlink" title="RAID level 10 – combining RAID 1 &amp; RAID 0"></a>RAID level 10 – combining RAID 1 &amp; RAID 0</h3><p>RAID10可以看做是RAID1和RAID0的结合。<br><a target="_blank" rel="noopener" href="http://www.prepressure.com/images/raid-level-1-and-0-striping-mirroring.svg"><img src="http://www.prepressure.com/images/raid-level-1-and-0-striping-mirroring.svg" alt="image"></a></p>
<p>RAID10的优点在于恢复数据速度很快，但相比与RAID5和6，使用设备的代价更大。</p>
<h4 id="mdadm-3"><a href="#mdadm-3" class="headerlink" title="mdadm"></a>mdadm</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$mdadm --create --verbose /dev/md1 --level=10 --raid-devices=4 /dev/loop4 /dev/loop5 /dev/loop6 /dev/loop7</span><br><span class="line">mdadm: layout defaults to n2</span><br><span class="line">mdadm: layout defaults to n2</span><br><span class="line">mdadm: chunk size defaults to 512K</span><br><span class="line">mdadm: size set to 2046976K</span><br><span class="line">mdadm: Defaulting to version 1.2 metadata</span><br><span class="line">mdadm: array /dev/md1 started.</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$mdadm --detail /dev/md1</span><br><span class="line">/dev/md1:</span><br><span class="line">        Version : 1.2</span><br><span class="line">  Creation Time : Tue Mar  7 17:44:43 2017</span><br><span class="line">     Raid Level : raid10</span><br><span class="line">     Array Size : 4093952 (3.90 GiB 4.19 GB)</span><br><span class="line">  Used Dev Size : 2046976 (1999.34 MiB 2096.10 MB)</span><br><span class="line">   Raid Devices : 4</span><br><span class="line">  Total Devices : 4</span><br><span class="line">    Persistence : Superblock is persistent</span><br><span class="line"></span><br><span class="line">    Update Time : Tue Mar  7 17:45:04 2017</span><br><span class="line">          State : clean </span><br><span class="line"> Active Devices : 4</span><br><span class="line">Working Devices : 4</span><br><span class="line"> Failed Devices : 0</span><br><span class="line">  Spare Devices : 0</span><br><span class="line"></span><br><span class="line">         Layout : near=2</span><br><span class="line">     Chunk Size : 512K</span><br><span class="line"></span><br><span class="line">           Name : st-integrat-node00:1  (local to host st-integrat-node00)</span><br><span class="line">           UUID : 643b371a:eeadc82d:7d4effee:cf00411c</span><br><span class="line">         Events : 17</span><br><span class="line"></span><br><span class="line">    Number   Major   Minor   RaidDevice State</span><br><span class="line">       0       7        4        0      active sync set-A   /dev/loop4</span><br><span class="line">       1       7        5        1      active sync set-B   /dev/loop5</span><br><span class="line">       2       7        6        2      active sync set-A   /dev/loop6</span><br><span class="line">       3       7        7        3      active sync set-B   /dev/loop7</span><br></pre></td></tr></table></figure>



<h4 id="device-mapper-1"><a href="#device-mapper-1" class="headerlink" title="device-mapper"></a>device-mapper</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 创建4个drive的RAID10，一半做镜像，所以大小为2倍drive sector大小。</span><br><span class="line">$dmsetup create test-raid10 --table &#x27;0 8192000 raid raid10 3 64 region_size 1024 4 - /dev/loop4 - /dev/loop5 - /dev/loop6 - /dev/loop7&#x27;</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$dmsetup status test-raid10</span><br><span class="line">0 8192000 raid raid10 4 AAAA 8192000/8192000 idle 0</span><br></pre></td></tr></table></figure>



<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>[1] RAID, <a target="_blank" rel="noopener" href="https://www.prepressure.com/library/technology/raid/">https://www.prepressure.com/library/technology/raid/</a></li>
<li>[2] Device-mapper, <a target="_blank" rel="noopener" href="https://wiki.gentoo.org/wiki/Device-mapper">https://wiki.gentoo.org/wiki/Device-mapper</a></li>
<li>[3] RAID-Setup, <a target="_blank" rel="noopener" href="https://raid.wiki.kernel.org/index.php/RAID_setup">https://raid.wiki.kernel.org/index.php/RAID_setup</a></li>
<li>[4] dm-raid, <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/device-mapper/dm-raid.txt">https://www.kernel.org/doc/Documentation/device-mapper/dm-raid.txt</a></li>
<li>[5] How To Create RAID Arrays with mdadm on Ubuntu 16.04, <a target="_blank" rel="noopener" href="https://www.digitalocean.com/community/tutorials/how-to-create-raid-arrays-with-mdadm-on-ubuntu-16-04">https://www.digitalocean.com/community/tutorials/how-to-create-raid-arrays-with-mdadm-on-ubuntu-16-04</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2018-10-12-repair-thinpool/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2018-10-12-repair-thinpool/" class="post-title-link" itemprop="url">repair-thinpool</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:35:02" itemprop="dateCreated datePublished" datetime="2024-03-10T12:35:02+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/storage/" itemprop="url" rel="index"><span itemprop="name">storage</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Repair-thin-pool-document"><a href="#Repair-thin-pool-document" class="headerlink" title="Repair thin-pool document"></a>Repair thin-pool document</h1><h3 id="Use-lvm-repair"><a href="#Use-lvm-repair" class="headerlink" title="Use lvm repair"></a>Use lvm repair</h3><p>If you would have latest lvm2 tools - you could have tried:</p>
<ol>
<li><p>deactive if pool is active, before deactive pool, you must to deactive the volumes created from pool. if volume is created by lvm, just umount volume and lvchange, but if volume is created by devicemapper, need manual remove volume and record the deviceId deviceName and table to activate volume. Deactive, actually, is the process of remove the file link of &#x2F;dev&#x2F;vg&#x2F;volume and* &#x2F;dev&#x2F;mapper&#x2F;vg-volume.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvchange -an vg</span><br></pre></td></tr></table></figure>
</li>
<li><p>repair meta and active pool</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvconvert --repair  vg/pool</span><br></pre></td></tr></table></figure>
</li>
<li><p>active pool</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvchange -ay vg</span><br></pre></td></tr></table></figure>

<p>Below are the steps which happen while running the consistency check:</p>
<ol>
<li>Creates a new, repaired copy of the metadata.<br>lvconvert runs the thin_repair command to read damaged metadata from<br>the existing pool metadata LV, and writes a new repaired copy to the<br>VG’s pmspare LV.</li>
<li>Replaces the thin pool metadata LV.<br>If step 1 is successful, the thin pool metadata LV is replaced with<br>the pmspare LV containing the corrected metadata. The previous thin<br>pool metadata LV, containing the damaged metadata, becomes visible<br>with the new name ThinPoolLV_tmetaN (where N is 0,1,…).</li>
</ol>
<p>but in my lvm (version 2.02.166(2)-RHEL7 (2016-11-16)), repair will not create new pmspare, it will direct use free vg to create new meta:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@tosqatest4 ~]# lvs -a silver_vg</span><br><span class="line">  LV                                VG        Attr       LSize   Pool                      Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  convoy_Linear_silver_data         silver_vg twi-aotz-- 894.25g                                  0.04   0.01                            </span><br><span class="line">  convoy_Linear_silver_data_meta0   silver_vg -wi-a-----   9.31g                                                                         </span><br><span class="line">  [convoy_Linear_silver_data_tdata] silver_vg Twi-ao---- 894.25g                                                                         </span><br><span class="line">  [convoy_Linear_silver_data_tmeta] silver_vg ewi-ao----   9.31g                                                                         </span><br><span class="line">  thinvolume                        silver_vg Vwi-aotz--   1.00g convoy_Linear_silver_data        40.04</span><br></pre></td></tr></table></figure>

<p>So pmspare device just a free space device nor a mirror of metadata, if not, we can add pv to vg for repair.</p>
<h3 id="Use-manual-repair"><a href="#Use-manual-repair" class="headerlink" title="Use manual repair"></a>Use manual repair</h3><p>With older tools - you need to go in these manual step:</p>
<ol>
<li><p>create temporary small LV</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvcreate -an -Zn -L10 --name temp vg</span><br></pre></td></tr></table></figure>
</li>
<li><p>replace pool’s metadata volume with this tempLV</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvconvert --thinpool vg/pool  --poolmetadata temp</span><br></pre></td></tr></table></figure></li>
</ol>
<p>(say ‘y’ to swap)</p>
<ol>
<li><p>activate &amp; repair metadata from ‘temp’ volume - you will likely need another volume where to store repaire metadata -</p>
<p>so create:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lvcreate -Lat_least_as_big_as_temp  --name repaired  vg</span><br><span class="line">lvchage -ay vg/temp</span><br><span class="line">thin_repair -i /dev/vg/temp  /dev/vg/repaired</span><br></pre></td></tr></table></figure>

<p>if everything when fine - compare visualy ‘transaction_id’ of repaired metadata (thin_dump &#x2F;dev&#x2F;vg&#x2F;repaired)</p>
<ol>
<li><p>swap deactivated repaired volume back to your thin-pool</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lvchange -an vg/repaired</span><br><span class="line">lvconvert --thinpool vg/pool --poolmetadata repaired</span><br></pre></td></tr></table></figure></li>
</ol>
<p>try to activate pool - if it doesn’t work report more problems.</p>
<h2 id="Metadata-space-exhaustion"><a href="#Metadata-space-exhaustion" class="headerlink" title="Metadata space exhaustion"></a>Metadata space exhaustion</h2><p>Metadata space exhaustion can lead to inconsistent thin pool metadata<br>and inconsistent file systems, so the response requires offline<br>checking and repair.</p>
<ol>
<li><p>Deactivate the thin pool LV, or reboot the system if this is not</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">possible.</span><br></pre></td></tr></table></figure>
</li>
<li><p>Repair thin pool with lvconvert –repair.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">See &quot;Metadata check and repair&quot;.</span><br></pre></td></tr></table></figure>
</li>
<li><p>Extend pool metadata space with lvextend VG&#x2F;ThinPoolLV_tmeta.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">See &quot;Manually manage free metadata space of a thin pool LV&quot;.</span><br></pre></td></tr></table></figure>
</li>
<li><p>Check and repair file system with fsck.</p>
</li>
</ol>
</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2018-10-12-kmp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2018-10-12-kmp/" class="post-title-link" itemprop="url">kmp</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:35:02" itemprop="dateCreated datePublished" datetime="2024-03-10T12:35:02+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/coding/" itemprop="url" rel="index"><span itemprop="name">coding</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>KMP算法用于做字符串匹配, 是计算机中经常用到的算法. 大多数都文章比较难懂, 这里参考了<a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html">阮一封</a>的博客文章, 比较通俗易懂, 但是没有详细解释Next表怎么具体算出来, 只是给出了概念的解释. 这里给出更完整的算法实现和解释.</p>
<h4 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h4><p>KMP的基本思想非常简单, 举例来说, 现在判断字符串”ABCDABD”是否在字符串”BBC ABCDAB ABCDABCDABDE”中.</p>
<ol>
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050103.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050103.png" alt="img"></a></p>
<p>首先，字符串”BBC ABCDAB ABCDABCDABDE”的第一个字符与搜索词”ABCDABD”的第一个字符，进行比较。因为B与A不匹配，所以搜索词后移一位。</p>
<ol start="2">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050104.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050104.png" alt="img"></a></p>
<p>因为B与A不匹配，搜索词再往后移。</p>
<ol start="3">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050105.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050105.png" alt="img"></a></p>
<p>就这样，直到字符串有一个字符，与搜索词的第一个字符相同为止。</p>
<ol start="4">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050106.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050106.png" alt="img"></a></p>
<p>接着比较字符串和搜索词的下一个字符，还是相同。</p>
<ol start="5">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png" alt="img"></a></p>
<p>直到字符串有一个字符，与搜索词对应的字符不相同为止。</p>
<ol start="6">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050108.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050108.png" alt="img"></a></p>
<p>这时，最自然的反应是，将搜索词整个后移一位，再从头逐个比较。这样做虽然可行，但是效率很差，因为你要把”搜索位置”移到已经比较过的位置，重比一遍。</p>
<ol start="7">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png" alt="img"></a></p>
<p>一个基本事实是，当空格与D不匹配时，你其实知道前面六个字符是”ABCDAB”。KMP算法的想法是，设法利用这个已知信息，不要把”搜索位置”移回已经比较过的位置，继续把它向后移，这样就提高了效率。</p>
<ol start="8">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050109.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050109.png" alt="img"></a></p>
<p>怎么做到这一点呢？可以针对搜索词，算出一张《部分匹配表》（Partial Match Table）。这张表是如何产生的，后面再介绍，这里只要会用就可以了。</p>
<ol start="9">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050107.png" alt="img"></a></p>
<p>已知空格与D不匹配时，前面六个字符”ABCDAB”是匹配的。查表可知，最后一个匹配字符B对应的”部分匹配值”为2，因此按照下面的公式算出向后移动的位数：</p>
<blockquote>
<p>　　移动位数 &#x3D; 已匹配的字符数 - 对应的部分匹配值</p>
</blockquote>
<p>因为 6 - 2 等于4，所以将搜索词向后移动4位。</p>
<ol start="10">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050110.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050110.png" alt="img"></a></p>
<p>因为空格与Ｃ不匹配，搜索词还要继续往后移。这时，已匹配的字符数为2（”AB”），对应的”部分匹配值”为0。所以，移动位数 &#x3D; 2 - 0，结果为 2，于是将搜索词向后移2位。</p>
<ol start="11">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050111.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050111.png" alt="img"></a></p>
<p>因为空格与A不匹配，继续后移一位。</p>
<ol start="12">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050112.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050112.png" alt="img"></a></p>
<p>逐位比较，直到发现C与D不匹配。于是，移动位数 &#x3D; 6 - 2，继续将搜索词向后移动4位。</p>
<ol start="13">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050113.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050113.png" alt="img"></a></p>
<p>逐位比较，直到搜索词的最后一位，发现完全匹配，于是搜索完成。如果还要继续搜索（即找出全部匹配），移动位数 &#x3D; 7 - 0，再将搜索词向后移动7位，这里就不再重复了。</p>
<ol start="14">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050114.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050114.png" alt="img"></a></p>
<p>下面介绍《部分匹配表》是如何产生的。</p>
<p>首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。</p>
<ol start="15">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050109.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050109.png" alt="img"></a></p>
<p>“部分匹配值”就是”前缀”和”后缀”的最长的共有元素的长度。以”ABCDABD”为例，</p>
<blockquote>
<p>　　－　“A”的前缀和后缀都为空集，共有元素的长度为0；</p>
<p>　　－　“AB”的前缀为[A]，后缀为[B]，共有元素的长度为0；</p>
<p>　　－　“ABC”的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0；</p>
<p>　　－　“ABCD”的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0；</p>
<p>　　－　“ABCDA”的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为”A”，长度为1；</p>
<p>　　－　“ABCDAB”的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为”AB”，长度为2；</p>
<p>　　－　“ABCDABD”的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。</p>
</blockquote>
<ol start="16">
<li></li>
</ol>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050112.png"><img src="http://www.ruanyifeng.com/blogimg/asset/201305/bg2013050112.png" alt="img"></a></p>
<p>“部分匹配”的实质是，有时候，字符串头部和尾部会有重复。比如，”ABCDAB”之中有两个”AB”，那么它的”部分匹配值”就是2（”AB”的长度）。搜索词移动的时候，第一个”AB”向后移动4位（字符串长度-部分匹配值），就可以来到第二个”AB”的位置。</p>
<p>####算法实现</p>
<p>从上述思想来看, KMP的核心在于计算Next(部分匹配表)表, 其他的就是按照一个公式去移动而已. 我们来看看这个表用算法如何构造. 从15我们知道, Next就是”部分匹配值”就是”前缀”和”后缀”的最长的共有元素的长度.</p>
<p>我们先用最直观的做法来写这段代码, 然后再来优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func Next(str string) []int &#123;</span><br><span class="line">    length := len(str)</span><br><span class="line">    next := make([]int, length) // next数组</span><br><span class="line">    for q := 1; q &lt; length; q++ &#123;</span><br><span class="line">        m := 0</span><br><span class="line">        for k := 0; k &lt; q; k++ &#123;</span><br><span class="line">            if str[:k+1] == str[q-k:q+1] &amp;&amp; k+1 &gt; m&#123; //如果前缀等于后缀, 并且长度是最长的, 就替换m</span><br><span class="line">                m = k+1</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        next[q] = m // m是写入next数组, 循环q</span><br><span class="line">    &#125;</span><br><span class="line">    return next</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码将next数组计算出来, 符合正常的code思路, 但是复杂度是O(n^2), 显然不符合KMP的思想. 我们来做一些优化. 首先, 按照next的特性, 每次不需要回溯到0, 而是充分利用next特性回溯到已经匹配的字串, 如果不中再去找上一个, 算法见:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">func Next(str string) []int &#123;</span><br><span class="line">    length := len(str)</span><br><span class="line">    next := make([]int, length)</span><br><span class="line">    next[0] = 0 // 初始化为0, 表示没有</span><br><span class="line">    for q := 1; q &lt; length; q++ &#123;</span><br><span class="line">        k := next[q - 1] // 只需要退回到前一个的next[q-1]位置, 而不用回到0</span><br><span class="line">        for k &gt; 0 &amp;&amp; str[k] != str[q] &#123; // 如果后一个位置不相等, 再往前回溯</span><br><span class="line">            k = next[k] // 为什么这里不直接跳回到0呢, 因为next[k]表示前面已经匹配的, 而不需要退到起点, 先从最大长度往前回溯</span><br><span class="line">        &#125;</span><br><span class="line">        if str[k] == str[q] &#123;</span><br><span class="line">            // 如果下一个字符相等, 将将k + 1, 由于前面的字串肯定是相等的, 不需要在比较</span><br><span class="line">            next[q] = k + 1</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            next[q] = 0 // 如果不相等</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return next</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>改进后的算法时间复杂度为O(2n)</p>
<p>这种写法看起来不是很美观, 但是可读性更强, 有点写法会将初始值为-1, 然后将k :&#x3D; next[q - 1] 和 k &#x3D; next[k]合在一起, 把 next[q] &#x3D; k + 1和 next[q] &#x3D; 0也合在一起, 这种”炫技” 行为我个人是非常不喜欢的, 看起来简洁但是将算法思想隐藏了, 可理解性很差. 同样我也不喜欢用任何lamda写法, 除非语言层面对此有性能优化, 否则只是用来恶心看代码的人.</p>
<p>按照这个思想写KMP的算法就非常简单了:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">func kmp(str1, str2 string) bool &#123;</span><br><span class="line">    next := Next(str2)</span><br><span class="line">    i := 0 // i 是str1的index</span><br><span class="line">    j := 0 // j 是str2的index</span><br><span class="line">    length := len(str1)</span><br><span class="line">    for i &lt; length &#123;</span><br><span class="line">        if str1[i+j] == str2[j] &#123;</span><br><span class="line">            j++</span><br><span class="line">            if j == len(str2) &#123;</span><br><span class="line">                // 完全匹配</span><br><span class="line">                return true</span><br><span class="line">            &#125;</span><br><span class="line">            continue</span><br><span class="line">        &#125;</span><br><span class="line">        if j == 0 &#123; // j==0 字节i++ 跳过</span><br><span class="line">            i++</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            i = i + j - next[j-1]//移动位数 = 已匹配的字符数 - 对应的部分匹配值</span><br><span class="line">            j = next[j - 1] // j回溯到记录位置</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>KMP算法的复杂度为O(M+N), 其他写法会更简洁, 但是同样为了可读性, 情愿写的罗嗦一点.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">    str1 := &quot;BBC ABCDAB ABCDABCDABDE&quot;</span><br><span class="line">    str := &quot;ABCDABD&quot;</span><br><span class="line">    fmt.Println(kmp(str1, str))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>带上术例子进行计算, 总共循环次数为15次, 其中计算next数组总共只计算了7次.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/10/2018-10-12-lvconvert-down/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/2018-10-12-lvconvert-down/" class="post-title-link" itemprop="url">lvconvert-down</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-10 12:35:02" itemprop="dateCreated datePublished" datetime="2024-03-10T12:35:02+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/system/" itemprop="url" rel="index"><span itemprop="name">system</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>记录一个kernel bug.</p>
<p>在组建中调用了lvconvert生成存储池, 但是测试告诉我过程失败并且机器重启了, 通过抓kdump生成以下日志:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[  983.179047] BUG kmalloc-256(4:099fef32f6df55082271a9ab572acec8251aa754a14a60444d7ce4cb110be56f) (Tainted: G    B          ------------ T): Objects remaining in kmalloc-256(4:099fef32f6df55082271a9ab572acec8251aa754a14a60444d7ce4cb110be56f</span><br><span class="line">[  983.179890] -----------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">[  983.180762] INFO: Slab 0xffffea000cae8840 objects=16 used=9 fp=0xffff88032ba21b00 flags=0x2fffff00000080</span><br><span class="line">[  983.181181] CPU: 3 PID: 25070 Comm: lvconvert Tainted: G    B          ------------ T 3.10.0-327.el7.x86_64 #1</span><br><span class="line">[  983.181182] Hardware name: Red Hat KVM, BIOS 0.5.1 01/01/2011</span><br><span class="line">[  983.181183]  ffffea000cae8840 00000000c255adbf ffff88018d43baa8 ffffffff816351f1</span><br><span class="line">[  983.181186]  ffff88018d43bb80 ffffffff811beac4 0000000000000020 ffff88018d43bb90</span><br><span class="line">[  983.181188]  ffff88018d43bb40 656a624f00000000 616d657220737463 6e6920676e696e69</span><br><span class="line">[  983.181190] Call Trace:</span><br><span class="line">[  983.181195]  [&lt;ffffffff816351f1&gt;] dump_stack+0x19/0x1b</span><br><span class="line">[  983.181203]  [&lt;ffffffff811beac4&gt;] slab_err+0xb4/0xe0</span><br><span class="line">[  983.181206]  [&lt;ffffffff811c1f33&gt;] ? __kmalloc+0x1f3/0x230</span><br><span class="line">[  983.181208]  [&lt;ffffffff811c316b&gt;] ? kmem_cache_close+0x12b/0x2f0</span><br><span class="line">[  983.181210]  [&lt;ffffffff811c318c&gt;] kmem_cache_close+0x14c/0x2f0</span><br><span class="line">[  983.181212]  [&lt;ffffffff811c35c4&gt;] __kmem_cache_shutdown+0x14/0x80</span><br><span class="line">[  983.181215]  [&lt;ffffffff8118ceaf&gt;] kmem_cache_destroy+0x3f/0xe0</span><br><span class="line">[  983.181217]  [&lt;ffffffff811d4949&gt;] kmem_cache_destroy_memcg_children+0x89/0xb0</span><br><span class="line">[  983.181221]  [&lt;ffffffff8118ce84&gt;] kmem_cache_destroy+0x14/0xe0</span><br><span class="line">[  983.181231]  [&lt;ffffffff8121705e&gt;] bioset_free+0xce/0x110</span><br><span class="line">[  983.181250]  [&lt;ffffffffa0002fa0&gt;] __dm_destroy+0x1b0/0x340 [dm_mod]</span><br><span class="line">[  983.181257]  [&lt;ffffffffa00047e3&gt;] dm_destroy+0x13/0x20 [dm_mod]</span><br><span class="line">[  983.181263]  [&lt;ffffffffa000a34e&gt;] dev_remove+0x11e/0x180 [dm_mod]</span><br><span class="line">[  983.181268]  [&lt;ffffffffa000a230&gt;] ? dev_suspend+0x250/0x250 [dm_mod]</span><br><span class="line">[  983.181274]  [&lt;ffffffffa000aa25&gt;] ctl_ioctl+0x255/0x500 [dm_mod]</span><br><span class="line">[  983.181278]  [&lt;ffffffff81271b94&gt;] ? SYSC_semtimedop+0x264/0xd10</span><br><span class="line">[  983.181287]  [&lt;ffffffffa000ace3&gt;] dm_ctl_ioctl+0x13/0x20 [dm_mod]</span><br><span class="line">[  983.181289]  [&lt;ffffffff811f1ef5&gt;] do_vfs_ioctl+0x2e5/0x4c0</span><br><span class="line">[  983.181292]  [&lt;ffffffff811e05ee&gt;] ? ____fput+0xe/0x10</span><br><span class="line">[  983.181294]  [&lt;ffffffff811f2171&gt;] SyS_ioctl+0xa1/0xc0</span><br><span class="line">[  983.181298]  [&lt;ffffffff81645909&gt;] system_call_fastpath+0x16/0x1b</span><br></pre></td></tr></table></figure>

<p>看起来是lvconvert过程中缓存分配出现错误, 查到这一步基本无从下手了, 只能google搜索. 在docker项目中发现有相似的情况<a target="_blank" rel="noopener" href="https://github.com/moby/moby/issues/29879">https://github.com/moby/moby/issues/29879</a>, 出问题的三个网址都是3.10的kernel, 回到说是kernel问题, 升到4.16.7-1.el7.elrepo.x86_64没有问题.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">John Doe</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
